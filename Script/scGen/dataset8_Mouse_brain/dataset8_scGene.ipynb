{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scgen\n",
    "# Import package \n",
    "# Main using package here is scanpy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import scgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset8_Mouse_brain\n"
     ]
    }
   ],
   "source": [
    "base_name = os.path.basename(os.getcwd())\n",
    "print(base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n",
      "scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 \n"
     ]
    }
   ],
   "source": [
    "print(sc.__version__)\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "# sc.settings.set_figure_params(dpi=300, frameon=False)  # low dpi (dots per inch) yields small inline figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base_name, dpi=300, fig_type = \".png\"):\n",
    "    output_dir = os.path.dirname(base_name)\n",
    "    if not output_dir==\"\" and os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    fn, fe = os.path.splitext(base_name)\n",
    "    if(fe == \"\"):\n",
    "        base_name = base_name + fig_type\n",
    "    pl.savefig(base_name, dpi=dpi)\n",
    "    pl.close()\n",
    "    \n",
    "def plotTSNE(adata, color_group, n_pcs=20, perplexity=30, save_filename='tsne', use_repx = False):\n",
    "    #adata.var_names_make_unique()\n",
    "    random.seed(42)\n",
    "    if use_repx:\n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, use_rep='X')\n",
    "    else:    \n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, n_jobs=20)\n",
    "    sc.pl.tsne(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename) \n",
    "    \n",
    "def plotUMAP(adata, color_group, save_filename, use_repx = False):\n",
    "    \n",
    "#     if use_repx:\n",
    "#         sc.pp.neighbors(adata, use_rep='X')\n",
    "#     else:    \n",
    "#         sc.pp.neighbors(adata,n_neighbors=10, n_pcs=20)\n",
    "        \n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 847649 × 18233 \n",
      "Index(['P60CBRep1P1_GACTCTACACCC', 'P60CBRep1P1_TATTATATCTAA',\n",
      "       'P60CBRep1P1_GCGTCGCCAGTT'],\n",
      "      dtype='object')\n",
      "Index(['0610005C13Rik', '0610007P14Rik', '0610009B22Rik'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read data from read count text table, data from R: genes x cells\n",
    "expression_data = '../../dataset/Mouse_brain/dropviz_and_nuclei_combined_UMI_log_transposed.txt'\n",
    "adata = sc.read_text(expression_data, delimiter='\\t', first_column_names=True, dtype='float64')\n",
    "print(adata)  # 6954 x 1328\n",
    "print(adata.obs_names[0:3])\n",
    "print(adata.var_names[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(847649, 2)\n",
      "Index(['batch', 'cell_type'], dtype='object')\n",
      "Index(['P60CBRep1P1_GACTCTACACCC', 'P60CBRep1P1_TATTATATCTAA',\n",
      "       'P60CBRep1P1_GCGTCGCCAGTT', 'P60CBRep1P1_CTATCGATTTCN',\n",
      "       'P60CBRep1P1_GTACCTGAGCCT', 'P60CBRep1P1_TCGCTTAGGCAT',\n",
      "       'P60CBRep1P1_CAGCCCCCGGCA', 'P60CBRep1P1_GTCAATGCAGAC',\n",
      "       'P60CBRep1P1_GCCCTATCTTGG', 'P60CBRep1P1_GCTACCTGAACN',\n",
      "       ...\n",
      "       'Nuclei_cell_156040', 'Nuclei_cell_156041', 'Nuclei_cell_156042',\n",
      "       'Nuclei_cell_156043', 'Nuclei_cell_156044', 'Nuclei_cell_156045',\n",
      "       'Nuclei_cell_156046', 'Nuclei_cell_156047', 'Nuclei_cell_156048',\n",
      "       'Nuclei_cell_156049'],\n",
      "      dtype='object', length=847649)\n"
     ]
    }
   ],
   "source": [
    "# Read sample into a pandas series\n",
    "cell_info = \"../../dataset/Mouse_brain/dropviz_and_nuclei_combined_cell_info.txt\"\n",
    "sample_adata = pd.read_csv(cell_info,header=0, index_col=0, sep='\\t')\n",
    "print(sample_adata.values.shape)\n",
    "print(sample_adata.keys())\n",
    "print(sample_adata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "847649\n",
      "847649\n"
     ]
    }
   ],
   "source": [
    "adata.obs['batch'] = sample_adata.loc[adata.obs_names, \"batch\"]\n",
    "print(len(adata.obs['batch']))\n",
    "adata.obs['cell_type'] = sample_adata.loc[adata.obs_names, \"cell_type\"]\n",
    "print(len(adata.obs['cell_type']))\n",
    "# Save output into h5ad, easy to access \n",
    "# adata.write_h5ad(os.path.join(data_dir,'hvg_dataset2_cellatlas.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA with n_comps = 50\n",
      "    finished (0:13:26.66)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:04:16.82) --> added to `.uns['neighbors']`\n",
      "    'distances', distances for each pair of neighbors\n",
      "    'connectivities', weighted adjacency matrix\n",
      "computing UMAP\n",
      "    using 'X_pca' with n_pcs = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xm/.local/lib/python3.7/site-packages/umap/spectral.py:229: UserWarning: Embedding a total of 2 separate connected components using meta-embedding (experimental)\n",
      "  n_components\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:18:45.90) --> added\n",
      "    'X_umap', UMAP coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata,n_neighbors=15, n_pcs=20)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n"
     ]
    }
   ],
   "source": [
    "sc.pl.umap(adata, color=[\"batch\"], wspace=.3, show=False)\n",
    "save_images('dataset10_umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n",
      "    finished (1:08:03.21) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "color_group = [\"cell_type\",\"batch\"]\n",
    "plotTSNE(adata, color_group, 20, 90, base_name + '_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0822 17:50:40.984180 140360651884352 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:42: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0822 17:50:40.986573 140360651884352 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 17:50:43.833326 140360651884352 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0822 17:50:43.835178 140360651884352 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:78: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0822 17:50:43.836425 140360651884352 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:78: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0822 17:50:43.837859 140360651884352 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:79: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0822 17:50:44.062743 140360651884352 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:80: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0822 17:50:44.222927 140360651884352 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:82: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0822 17:50:44.385319 140360651884352 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:134: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0822 17:50:44.534928 140360651884352 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:177: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0822 17:50:45.454994 140360651884352 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:58: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Create a network\")\n",
    "t1 = time.time()\n",
    "# Initialize scGen with input is number of genes\n",
    "import scgen\n",
    "network = scgen.VAEArith(x_dimension=adata.shape[1], model_path=\"./results_cellatlas/batch_hvg\")\n",
    "# Need to check batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a network\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a network\")\n",
    "# Train scGen with nb epochs = 100\n",
    "# Requirement: adata should contain 2 vector: adata.obs[\"cell_type\"] and adata.obs[\"batch\"]\n",
    "network.train(train_data=adata, n_epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import anndata\n",
    "# Using trained model to correct, normalize data \n",
    "# Using batch removal function from scGen package \n",
    "\n",
    "#corrected_adata = scgen.batch_removal(network, total_ann)\n",
    "\n",
    "# In case this function does not work, replace batch_removal function by this function: batch_removal_v2\n",
    "# Hoa Tran\n",
    "def batch_removal_v2(network, adata):\n",
    "    if sparse.issparse(adata.X):\n",
    "        latent_all = network.to_latent(adata.X.A)\n",
    "    else:\n",
    "        latent_all = network.to_latent(adata.X)\n",
    "    adata_latent = anndata.AnnData(latent_all)\n",
    "    adata_latent.obs[\"cell_type\"] = adata.obs[\"cell_type\"].tolist()\n",
    "    adata_latent.obs[\"batch\"] = adata.obs[\"batch\"].tolist()\n",
    "    adata_latent.obs[\"cell_name\"] = adata.obs[\"cell_name\"].tolist()   #Hoa keep cell name infos\n",
    "    unique_cell_types = np.unique(adata_latent.obs[\"cell_type\"])\n",
    "    shared_ct = []\n",
    "    not_shared_ct = []\n",
    "    for cell_type in unique_cell_types:\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        if len(np.unique(temp_cell.obs[\"batch\"])) < 2:\n",
    "            cell_type_ann = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "            not_shared_ct.append(cell_type_ann)\n",
    "            continue\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        batch_list = {}\n",
    "        batch_ind = {}\n",
    "        max_batch = 0\n",
    "        max_batch_ind = \"\"\n",
    "        batches = np.unique(temp_cell.obs[\"batch\"])\n",
    "        for i in batches:\n",
    "            temp = temp_cell[temp_cell.obs[\"batch\"] == i]\n",
    "            temp_ind = temp_cell.obs[\"batch\"] == i\n",
    "            if max_batch < len(temp):\n",
    "                max_batch = len(temp)\n",
    "                max_batch_ind = i\n",
    "            batch_list[i] = temp\n",
    "            batch_ind[i] = temp_ind\n",
    "        max_batch_ann = batch_list[max_batch_ind]\n",
    "        for study in batch_list:\n",
    "            delta = np.average(max_batch_ann.X, axis=0) - np.average(batch_list[study].X, axis=0)\n",
    "            batch_list[study].X = delta + batch_list[study].X\n",
    "            temp_cell[batch_ind[study]].X = batch_list[study].X\n",
    "        shared_ct.append(temp_cell)\n",
    "    all_shared_ann = anndata.AnnData.concatenate(*shared_ct, batch_key=\"concat_batch\")\n",
    "    del all_shared_ann.obs[\"concat_batch\"]\n",
    "    if len(not_shared_ct) < 1:\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_shared_ann.X, use_data=True))\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected\n",
    "    else:\n",
    "        all_not_shared_ann = anndata.AnnData.concatenate(*not_shared_ct, batch_key=\"concat_batch\")\n",
    "        all_corrected_data = anndata.AnnData.concatenate(all_shared_ann, all_not_shared_ann, batch_key=\"concat_batch\")\n",
    "        del all_corrected_data.obs[\"concat_batch\"]\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_corrected_data.X, use_data=True), )\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist() + all_not_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_name\"].tolist()     #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1 day, 6:54:17.605938\n",
      "AnnData object with n_obs × n_vars = 847649 × 18233 \n",
      "    obs: 'cell_type', 'batch', 'cell_name'\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct data\")\n",
    "# Correct data using batch_removal function\n",
    "# Input: adata and network model \n",
    "adata.obs['cell_name'] = adata.obs_names\n",
    "adata.obs['batch']=adata.obs['batch'].astype('category')\n",
    "corrected_adata = batch_removal_v2(network, adata)\n",
    "t2 = time.time()\n",
    "print('Took '+str(timedelta(seconds=t2-t1)))\n",
    "# corrected_adata = scgen.batch_removal(network, adata1)\n",
    "# For verification\n",
    "# print(corrected_adata.obs['cell_name'][350:400])\n",
    "# print(corrected_adata.obs['cell_type'][350:400])\n",
    "corrected_adata.obs_names[1:10]\n",
    "print(corrected_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "time_taken = t2 - t1\n",
    "time_taken_mins = divmod(time_taken, 60)\n",
    "time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "hours_mins, hours_secs = divmod( rest, 60)\n",
    "print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "print('Took minutes: '+str(time_taken_mins))\n",
    "print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "usecase_name = 'scGen'\n",
    "filename = 'hvg_scGen_exetime.csv'\n",
    "\n",
    "data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "       'exetimehours': str(time_taken_hours),\n",
    "       'exetimemins': str(hours_mins),\n",
    "       'exetimesecs':str(round(hours_secs))} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['exetime'])\n",
    "print(df)\n",
    "df.to_csv(base_name + \"_exetime.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(corrected_adata, svd_solver='arpack', n_comps=20)\n",
    "corrected_adata.obsm['X_pca'] *= -1 # multiply by -1 to match Seurat, same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTSNE(corrected_adata, color_group, 20, 90, base_name + '_scgene_corrected_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing '.csv' files to dataset8_Mouse_brain_results\n"
     ]
    }
   ],
   "source": [
    "adata.write_csvs(base_name + \"_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing '.csv' files to dataset8_Mouse_brain_corrected_results\n"
     ]
    }
   ],
   "source": [
    "corrected_adata.write_csvs(base_name + \"_corrected_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
