{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.4 anndata==0.6.18 numpy==1.16.2 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.3 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 \n"
     ]
    }
   ],
   "source": [
    "import scgen\n",
    "print(scgen.__version__)\n",
    "# Import package \n",
    "# Main using package here is scanpy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "# sc.settings.set_figure_params(dpi=300, frameon=False)  # low dpi (dots per inch) yields small inline figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data_n3/home/hoatran/python-workspace/dca_scGen\n"
     ]
    }
   ],
   "source": [
    "# Create folder to save the results \n",
    "import os\n",
    "dirname = os.getcwd()\n",
    "print(dirname)\n",
    "data_dir = os.path.join(dirname, './data/dataset2_cellatlas/')\n",
    "if not os.path.exists('./results_cellatlas/'): os.makedirs('./results_cellatlas/')\n",
    "\n",
    "if not os.path.exists('./results_cellatlas/scGen_results/'): os.makedirs('./results_cellatlas/scGen_results/')\n",
    "    \n",
    "save_dir = os.path.join(dirname, './results_cellatlas/scGen_results/')\n",
    "def save_images(basename):\n",
    "    if not os.path.exists('./figures_cellatlas/'): os.makedirs('./figures_cellatlas/')\n",
    "    \n",
    "    if not os.path.exists('./figures_cellatlas/scGen_results/'): os.makedirs('./figures_cellatlas/scGen_results/')\n",
    "    outname = './figures_cellatlas/scGen_results/' + basename + '.png'\n",
    "    pl.savefig(outname, dpi=150)\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected_adata = sc.read_h5ad(os.path.join(data_dir,'correction_dataset1_uc3.h5ad'))\n",
    "# sc.tl.pca(corrected_adata, svd_solver='arpack', n_comps=20)\n",
    "# print(corrected_adata)\n",
    "# corrected_adata.obsm['X_pca'] *= -1  # multiply by -1 to match Seurat\n",
    "# save_dir = os.path.join(dirname, './results/scGen_results/')\n",
    "# corrected_adata.write_csvs(save_dir, skip_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from read count text table, data from R: genes x cells\n",
    "adata = sc.read_text(os.path.join(data_dir,'dataset1_sm_uc3.txt'),delimiter='\\t',first_column_names=True,dtype='float64')\n",
    "print(adata)\n",
    "print(len(adata.obs_names))\n",
    "print(adata.var_names)\n",
    "# Read sample into a pandas series\n",
    "sample_adata = pd.read_csv(os.path.join(data_dir,'sample_sm_uc3.txt'),header=0, index_col=0, sep='\\t')\n",
    "print(sample_adata.values.shape)\n",
    "print(sample_adata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data have format genes x cells\n",
    "# But input for scanpy package require the format of cells x genes, samples x features\n",
    "# We need to copyt data into new adata object with inverse raw data \n",
    "# adata1 = sc.AnnData(adata.X.T)\n",
    "# adata1.var_names = adata.obs_names\n",
    "# adata1.obs_names = adata.var_names\n",
    "# adata1\n",
    "# # Save label information into adata object, same idea as Seurat \n",
    "# adata1.obs['cell_type'] = sample_adata.loc[adata1.obs_names,['celltype']]\n",
    "# adata1.obs['batch'] = sample_adata.loc[adata1.obs_names,['batch']]\n",
    "# print(len(adata1.obs['cell_type']))\n",
    "# print(len(adata1.obs['batch']))\n",
    "# Save output into h5ad, easy to access \n",
    "# adata1.write_h5ad(os.path.join(data_dir,'dataset1_uc3.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read and filter data\n"
     ]
    }
   ],
   "source": [
    "adata1 = sc.read_h5ad(os.path.join(data_dir,'dataset1_uc3.h5ad'))\n",
    "print('Read and filter data')\n",
    "# adata = sc.read_h5ad(os.path.join(data_dir,'filtered_dataset1_uc3.h5ad'))\n",
    "# adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered out 11 cells that have less than 300 genes expressed\n",
      "filtered out 9999 genes that are detected in less than 5 cells\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 565 × 16594 \n",
       "    obs: 'cell_type', 'batch', 'n_genes'\n",
       "    var: 'n_cells'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# Filtering data \n",
    "sc.pp.filter_cells(adata1, min_genes=300)\n",
    "sc.pp.filter_genes(adata1, min_cells=5)\n",
    "adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata1.write_h5ad(os.path.join(data_dir,'filtered_dataset1_uc3.h5ad'))\n",
    "# Visualization of raw data\n",
    "# sc.tl.pca(adata1, svd_solver='arpack')\n",
    "# sc.pp.neighbors(adata1,n_neighbors=10, n_pcs=20)\n",
    "# sc.tl.umap(adata1)\n",
    "# sc.pl.umap(adata1, color=[\"cell_type\",\"batch\"], wspace=.3, show=False)\n",
    "# save_images('umap_filtered_dataset1_uc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform and scale data\n",
    "sc.pp.log1p(adata1)\n",
    "sc.pp.scale(adata1)\n",
    "# sc.pp.neighbors(adata1,n_neighbors=10, n_pcs=20)\n",
    "# color_group = [\"batch\",\"cell_type\"]\n",
    "# plotTSNE(adata1, color_group, 20, 110, 'tsne_filtered_dataset1_uc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter_result = sc.pp.filter_genes_dispersion(adata1.X, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "# sc.pl.filter_genes_dispersion(filter_result, show=False)\n",
    "# save_images('scgen_filter_genes_dispersion')\n",
    "# adata1 = adata1[:, filter_result.gene_subset]\n",
    "# # color_group = [\"cell_type\",\"batch\"]\n",
    "# plotUMAP(adata1, color_group, 'umap_filtered_dataset1_uc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "# Initialize scGen with input is number of genes\n",
    "import scgen\n",
    "network = scgen.VAEArith(x_dimension=adata1.shape[1], model_path=\"./results/batch\")\n",
    "# Need to check batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train scGen with nb epochs = 100\n",
    "# Requirement: adata should contain 2 vector: adata.obs[\"cell_type\"] and adata.obs[\"batch\"]\n",
    "network.train(train_data=adata1, n_epochs=100, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import anndata\n",
    "# Using trained model to correct, normalize data \n",
    "# Using batch removal function from scGen package \n",
    "\n",
    "#corrected_adata = scgen.batch_removal(network, total_ann)\n",
    "\n",
    "# In case this function does not work, replace batch_removal function by this function: batch_removal_v2\n",
    "# Hoa Tran\n",
    "def batch_removal_v2(network, adata):\n",
    "    if sparse.issparse(adata.X):\n",
    "        latent_all = network.to_latent(adata.X.A)\n",
    "    else:\n",
    "        latent_all = network.to_latent(adata.X)\n",
    "    adata_latent = anndata.AnnData(latent_all)\n",
    "    adata_latent.obs[\"cell_type\"] = adata.obs[\"cell_type\"].tolist()\n",
    "    adata_latent.obs[\"batch\"] = adata.obs[\"batch\"].tolist()\n",
    "    adata_latent.obs[\"cell_name\"] = adata.obs[\"cell_name\"].tolist()   #Hoa keep cell name infos\n",
    "    unique_cell_types = np.unique(adata_latent.obs[\"cell_type\"])\n",
    "    shared_ct = []\n",
    "    not_shared_ct = []\n",
    "    for cell_type in unique_cell_types:\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        if len(np.unique(temp_cell.obs[\"batch\"])) < 2:\n",
    "            cell_type_ann = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "            not_shared_ct.append(cell_type_ann)\n",
    "            continue\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        batch_list = {}\n",
    "        batch_ind = {}\n",
    "        max_batch = 0\n",
    "        max_batch_ind = \"\"\n",
    "        batches = np.unique(temp_cell.obs[\"batch\"])\n",
    "        for i in batches:\n",
    "            temp = temp_cell[temp_cell.obs[\"batch\"] == i]\n",
    "            temp_ind = temp_cell.obs[\"batch\"] == i\n",
    "            if max_batch < len(temp):\n",
    "                max_batch = len(temp)\n",
    "                max_batch_ind = i\n",
    "            batch_list[i] = temp\n",
    "            batch_ind[i] = temp_ind\n",
    "        max_batch_ann = batch_list[max_batch_ind]\n",
    "        for study in batch_list:\n",
    "            delta = np.average(max_batch_ann.X, axis=0) - np.average(batch_list[study].X, axis=0)\n",
    "            batch_list[study].X = delta + batch_list[study].X\n",
    "            temp_cell[batch_ind[study]].X = batch_list[study].X\n",
    "        shared_ct.append(temp_cell)\n",
    "    all_shared_ann = anndata.AnnData.concatenate(*shared_ct, batch_key=\"concat_batch\")\n",
    "    del all_shared_ann.obs[\"concat_batch\"]\n",
    "    if len(not_shared_ct) < 1:\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_shared_ann.X, use_data=True))\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected\n",
    "    else:\n",
    "        all_not_shared_ann = anndata.AnnData.concatenate(*not_shared_ct, batch_key=\"concat_batch\")\n",
    "        all_corrected_data = anndata.AnnData.concatenate(all_shared_ann, all_not_shared_ann, batch_key=\"concat_batch\")\n",
    "        del all_corrected_data.obs[\"concat_batch\"]\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_corrected_data.X, use_data=True), )\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist() + all_not_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_name\"].tolist()     #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0:02:13.048766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['DoubleNeg_P10_S74', 'DoubleNeg_P10_S75', 'DoubleNeg_P10_S76',\n",
       "       'DoubleNeg_P10_S77', 'DoubleNeg_P10_S78', 'DoubleNeg_P10_S79',\n",
       "       'DoubleNeg_P10_S80', 'DoubleNeg_P10_S81', 'DoubleNeg_P10_S82'],\n",
       "      dtype='object', name='cell_name')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correct data using batch_removal function\n",
    "# Input: adata and network model \n",
    "adata1.obs['cell_name'] = adata1.obs_names\n",
    "corrected_adata = batch_removal_v2(network, adata1)\n",
    "t2 = time.time()\n",
    "print('Took '+str(timedelta(seconds=t2-t1)))\n",
    "# corrected_adata = scgen.batch_removal(network, adata1)\n",
    "# For verification\n",
    "# print(corrected_adata.obs['cell_name'][350:400])\n",
    "# print(corrected_adata.obs['cell_type'][350:400])\n",
    "corrected_adata.obs_names[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1557282884.3292305\n",
      "1557283017.3779964\n",
      "Took seconds: 0:02:13\n",
      "Took minutes: (2.0, 13.048765897750854)\n",
      "Took hours_minutes_seconds:  0.0 2.0 13.048765897750854\n",
      "         use_case exetime_secs exetimehours exetimemins exetimesecs\n",
      "extime  scGen_uc3          133          0.0         2.0          13\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "time_taken = t2 - t1\n",
    "time_taken_mins = divmod(time_taken, 60)\n",
    "time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "hours_mins, hours_secs = divmod( rest, 60)\n",
    "print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "print('Took minutes: '+str(time_taken_mins))\n",
    "print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "usecase_name = 'scGen_uc3'\n",
    "filename = 'scGen_uc3_extime.csv'\n",
    "\n",
    "data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "       'exetimehours': str(time_taken_hours),\n",
    "       'exetimemins': str(hours_mins),\n",
    "       'exetimesecs':str(round(hours_secs))} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['extime'])\n",
    "print(df)\n",
    "save_dir = '/data_n3/home/hoatran/python-workspace/dca_scGen/results/scGen_results/'\n",
    "df.to_csv(save_dir+filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data_n3/home/hoatran/python-workspace/dca_scGen/./results/'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(corrected_adata, svd_solver='arpack', n_comps=20)\n",
    "corrected_adata.obsm['X_pca'] *= -1 # multiply by -1 to match Seurat, same scale as total_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 565 × 16594 \n",
      "    obs: 'cell_type', 'batch', 'cell_name'\n",
      "    uns: 'pca', 'neighbors', 'cell_type_colors', 'batch_colors'\n",
      "    obsm: 'X_pca', 'X_umap', 'X_tsne'\n",
      "    varm: 'PCs'\n"
     ]
    }
   ],
   "source": [
    "# Corrected data have same dimensions as input data\n",
    "print(corrected_adata)\n",
    "corrected_adata.write_h5ad(os.path.join(save_dir,'scgen_correction_dataset1_uc3.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing '.csv' files to /data_n3/home/hoatran/python-workspace/dca_scGen/results/scGen_results\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(dirname, 'results/scGen_results/')\n",
    "corrected_adata.write_csvs(save_dir, skip_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_adata.obsm['X_pca'].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(mat, genesname, cellsname, filename, save_dir):\n",
    "    if isinstance(mat, np.ndarray):\n",
    "        df = pd.DataFrame(mat, columns=genesname, index=cellsname)\n",
    "    else:\n",
    "        df = pd.DataFrame(mat.toarray(), columns=genesname, index=cellsname)        \n",
    "    \n",
    "    df.to_csv(save_dir+filename)     \n",
    "filename = 'scGen_corrected_pca.csv'\n",
    "coln_pca = []\n",
    "for i in range(corrected_adata.obsm['X_pca'].shape[1]):\n",
    "    coln_pca.append(\"X_pca\"+str(i+1))\n",
    "    \n",
    "# save_dir = os.path.join(dirname, './data/dataset1_uc3/')\n",
    "write_to_csv(corrected_adata.obsm['X_pca'], coln_pca, corrected_adata.obs_names,filename, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08013981\n",
      "0.118949324\n",
      "                    use_case  sil_filtered  sil_corrected\n",
      "silscore  scGen_uc3_silscore      0.118949        0.08014\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(adata1, svd_solver='arpack')\n",
    "adata1.obsm.X_pca *= -1 # multiply by -1 to match Seurat, same scale as corrected_adata\n",
    "# Compute the silhouette coefficient score, compare the batch mixing level of filtered data and normalized data\n",
    "from sklearn.metrics import silhouette_score\n",
    "import seaborn as sns\n",
    "sil_orig = silhouette_score(adata1.obsm.X_pca[:,:20], adata1.obs['batch'])\n",
    "# sil_true = silhouette_score(corrected_adata.obsm.X_pca[:, :2], adata_true.obs.Group)\n",
    "sil_corr = silhouette_score(corrected_adata.obsm.X_pca[:,:20], corrected_adata.obs['batch'])\n",
    "print(sil_corr)\n",
    "print(sil_orig)\n",
    "usecase_name = 'scGen_uc3_silscore'\n",
    "data_sil = {'use_case':usecase_name, 'sil_filtered':sil_orig,\n",
    "       'sil_corrected': sil_corr} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df_score = pd.DataFrame(data_sil, index =['silscore'])\n",
    "print(df_score)\n",
    "save_dir = '/data_n3/home/hoatran/python-workspace/dca_scGen/results/scGen_results/'\n",
    "df_score.to_csv(save_dir+usecase_name+'.csv') \n",
    "# sil_score_ls = []\n",
    "# sil_score_ls.append(sil_orig)\n",
    "# sil_score_ls.append(sil_corr)\n",
    "# label_sil = ['Filtered', 'scGen_Normalized']\n",
    "# sns.barplot(x=label_sil, y=sil_score_ls)\n",
    "# pl.title('Silhouette Coef Batch Mixing')\n",
    "# save_images('scGen_silhouette_coeff_batch_label') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data_n3/home/hoatran/python-workspace/dca_scGen/results/scGen_results/'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(corrected_adata)\n",
    "colnu = []\n",
    "for i in range(corrected_adata.obsm['X_umap'].shape[1]):\n",
    "    colnu.append(\"UMAP\"+str(i+1))\n",
    "df = pd.DataFrame(corrected_adata.obsm['X_umap'], columns=colnu, index=corrected_adata.obs_names)\n",
    "df['batch'] = pd.Series(corrected_adata.obs['batch'], index=corrected_adata.obs_names)\n",
    "df['celltype'] = pd.Series(corrected_adata.obs['cell_type'], index=corrected_adata.obs_names)\n",
    "df.to_csv(sdir_name+'scGen_umap.csv')  \n",
    "\n",
    "colnt = []\n",
    "for i in range(corrected_adata.obsm['X_tsne'].shape[1]):\n",
    "    colnt.append(\"tSNE_\"+str(i+1))\n",
    "\n",
    "df = pd.DataFrame(corrected_adata.obsm['X_tsne'], columns=colnt, index=corrected_adata.obs_names)\n",
    "df['batch'] = pd.Series(corrected_adata.obs['batch'], index=corrected_adata.obs_names)\n",
    "df['celltype'] = pd.Series(corrected_adata.obs['cell_type'], index=corrected_adata.obs_names)\n",
    "df.to_csv(sdir_name+'scGen_tsne.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(corrected_adata.obs['cell_type'][1:10])\n",
    "# print(adata1.obs['cell_type'][1:10])\n",
    "import pandas as pd\n",
    "\n",
    "# def write_to_csv(mat, cellsname, genesname, filename, save_dir):\n",
    "#     if isinstance(mat, np.ndarray):\n",
    "#         df = pd.DataFrame(mat, columns=cellsname, index=genesname)\n",
    "#     else:\n",
    "#         df = pd.DataFrame(mat.toarray(), columns=cellsname, index=genesname)        \n",
    "    \n",
    "#     df.to_csv(save_dir+filename) \n",
    "    \n",
    "def write_to_csv(mat, genesname, cellsname, filename, save_dir):\n",
    "    if isinstance(mat, np.ndarray):\n",
    "        df = pd.DataFrame(mat, columns=genesname, index=cellsname)\n",
    "    else:\n",
    "        df = pd.DataFrame(mat.toarray(), columns=genesname, index=cellsname)        \n",
    "    \n",
    "    df.to_csv(save_dir+filename)     \n",
    "filename = 'scGen_corrected_d1_uc3.csv'\n",
    "# save_dir = os.path.join(dirname, './data/dataset1_uc3/')\n",
    "write_to_csv(corrected_adata.X, corrected_adata.var_names, corrected_adata.obs_names,filename, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell id: 10 in  Batch1\n",
      "Gene expression values before scGen:\n",
      "# of observations: 16594\n",
      "min: -4\n",
      "max: 18\n",
      "mean: 0.1\n",
      "Gene expression values after scGen:\n",
      "# of observations: 16594\n",
      "min: 0\n",
      "max: 9\n",
      "mean: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Check the changement of values before scGen and after batch correction using scGen \n",
    "import scipy.stats as st\n",
    "def describe_data(adata, ax, indx):    \n",
    "    desc = st.describe(adata.X[indx], axis=ax)\n",
    "    print('# of observations:', desc.nobs)\n",
    "    print('min: %d\\nmax: %d' % desc.minmax)\n",
    "    print('mean: %.1f' % desc.mean)\n",
    "    \n",
    "# Get one cell from batch 1, check the values before normalization and after   \n",
    "print(\"Cell id: 10 in \",adata1.obs['batch'][10])\n",
    "print(\"Gene expression values before scGen:\")\n",
    "describe_data(adata1, 0, 10) #cell id 10 in batch 1\n",
    "print(\"Gene expression values after scGen:\")\n",
    "describe_data(corrected_adata, 0, 10) #cell id 10 in batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell id: 500 in  Batch2\n",
      "Gene expression values before scGen:\n",
      "# of observations: 16594\n",
      "min: -7\n",
      "max: 17\n",
      "mean: -0.1\n",
      "Gene expression values after scGen:\n",
      "# of observations: 16594\n",
      "min: 0\n",
      "max: 6\n",
      "mean: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Get one cell from batch 2, check the values before normalization and after\n",
    "print(\"Cell id: 500 in \",adata1.obs['batch'][500])\n",
    "print(\"Gene expression values before scGen:\")\n",
    "describe_data(adata1, 0, 500)      # cell id 500 in batch 2  \n",
    "print(\"Gene expression values after scGen:\")\n",
    "describe_data(corrected_adata, 0, 500)      # cell id 500 in batch 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scgen:  1.0.0\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:00:04.55) --> added to `.uns['neighbors']`\n",
      "    'distances', distances for each pair of neighbors\n",
      "    'connectivities', weighted adjacency matrix\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:00:00.24) --> added to `.uns['neighbors']`\n",
      "    'distances', distances for each pair of neighbors\n",
      "    'connectivities', weighted adjacency matrix\n",
      "computing UMAP\n",
      "    finished (0:00:02.51) --> added\n",
      "    'X_umap', UMAP coordinates (adata.obsm)\n",
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n",
      "    finished (0:00:04.00) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "# Function to plot TSNE\n",
    "def plotTSNE(adata, color_group, n_pcs=20, perplexity=90, save_filename='tsne', use_repx = False):\n",
    "    #adata.var_names_make_unique()\n",
    "    if use_repx:\n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, use_rep='X')\n",
    "    else:    \n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity)\n",
    "    sc.pl.tsne(adata, color = color_group, show=False, wspace=.3)\n",
    "    save_images(save_filename) \n",
    "    \n",
    "def plotUMAP(adata, color_group, save_filename, use_repx = False):\n",
    "    \n",
    "    if use_repx:\n",
    "        sc.pp.neighbors(adata, use_rep='X')\n",
    "    else:    \n",
    "        sc.pp.neighbors(adata,n_neighbors=10, n_pcs=20)\n",
    "        \n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color = color_group, show=False)\n",
    "    save_images(save_filename)\n",
    "\n",
    "color_group = [\"cell_type\",\"batch\"]    \n",
    "# Visulization of normalized data\n",
    "print('scgen: ',scgen.__version__)\n",
    "sc.tl.pca(corrected_adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(corrected_adata,n_neighbors=10, n_pcs=20)\n",
    "plotUMAP(corrected_adata, color_group, 'umap_scGen_corrected_dataset1_uc3')\n",
    "plotTSNE(corrected_adata, color_group, 20, 90, 'tsne_scGen_corrected_dataset1_uc3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
