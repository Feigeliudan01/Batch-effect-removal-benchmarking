{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scgen\n",
    "# Import package \n",
    "# Main using package here is scanpy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import scgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset9_Human_cell_atlas\n"
     ]
    }
   ],
   "source": [
    "base_name = os.path.basename(os.getcwd())\n",
    "print(base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n",
      "scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 \n"
     ]
    }
   ],
   "source": [
    "print(sc.__version__)\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "# sc.settings.set_figure_params(dpi=300, frameon=False)  # low dpi (dots per inch) yields small inline figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base_name, dpi=300, fig_type = \".png\"):\n",
    "    output_dir = os.path.dirname(base_name)\n",
    "    if not output_dir==\"\" and os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    fn, fe = os.path.splitext(base_name)\n",
    "    if(fe == \"\"):\n",
    "        base_name = base_name + fig_type\n",
    "    pl.savefig(base_name, dpi=dpi)\n",
    "    pl.close()\n",
    "    \n",
    "def plotTSNE(adata, color_group, n_pcs=20, perplexity=30, save_filename='tsne', use_repx = False):\n",
    "    #adata.var_names_make_unique()\n",
    "    random.seed(42)\n",
    "    if use_repx:\n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, use_rep='X')\n",
    "    else:    \n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, n_jobs=20)\n",
    "    sc.pl.tsne(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename) \n",
    "    \n",
    "def plotUMAP(adata, color_group, save_filename, use_repx = False):\n",
    "    \n",
    "#     if use_repx:\n",
    "#         sc.pp.neighbors(adata, use_rep='X')\n",
    "#     else:    \n",
    "#         sc.pp.neighbors(adata,n_neighbors=10, n_pcs=20)\n",
    "        \n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 762000 × 18969 \n",
      "Index(['MantonCB1_HiSeq_1-AAACCTGAGGAGTTGC-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGAGGCATTGG-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCACAGACAG-1'],\n",
      "      dtype='object')\n",
      "Index(['ENSG00000238009', 'ENSG00000279457', 'ENSG00000228463'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read data from read count text table, data from R: genes x cells\n",
    "expression_data = '../../dataset/dataset9_Human_cell_atlas/HCA_all_UMI_filtered_log_transposed.txt'\n",
    "adata = sc.read_text(expression_data, delimiter='\\t', first_column_names=True, dtype='float64')\n",
    "print(adata)  # 6954 x 1328\n",
    "print(adata.obs_names[0:3])\n",
    "print(adata.var_names[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762000, 7)\n",
      "Index(['batch_detail', 'cell_type', 'donor', 'age', 'batch', 'sex', 'species'], dtype='object')\n",
      "Index(['MantonCB1_HiSeq_1-AAACCTGAGGAGTTGC-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGAGGCATTGG-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCACAGACAG-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCACAGATTC-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCACCCAGTG-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCACTGTGTA-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCAGACGCAA-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCAGGTCCAC-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGCAGTCTTCC-1',\n",
      "       'MantonCB1_HiSeq_1-AAACCTGGTTCCACGG-1',\n",
      "       ...\n",
      "       'MantonBM8_HiSeq_8-TTTGTCAAGTTTAGGA-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCACAACTGCTA-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCACACTGTGTA-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCAGTACCGCTG-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCAGTATCAGTC-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCAGTCAACATC-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCATCATTTGGG-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCATCCTCAACC-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCATCTGCCAGG-1',\n",
      "       'MantonBM8_HiSeq_8-TTTGTCATCTTGAGAC-1'],\n",
      "      dtype='object', length=762000)\n"
     ]
    }
   ],
   "source": [
    "# Read sample into a pandas series\n",
    "cell_info = \"./HCA_all_cell_info.txt\"\n",
    "sample_adata = pd.read_csv(cell_info,header=0, index_col=0, sep='\\t')\n",
    "print(sample_adata.values.shape)\n",
    "print(sample_adata.keys())\n",
    "print(sample_adata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762000\n",
      "762000\n"
     ]
    }
   ],
   "source": [
    "adata.obs['batch'] = sample_adata.loc[adata.obs_names, \"batch\"]\n",
    "print(len(adata.obs['batch']))\n",
    "adata.obs['cell_type'] = sample_adata.loc[adata.obs_names, \"cell_type\"]\n",
    "print(len(adata.obs['cell_type']))\n",
    "# Save output into h5ad, easy to access \n",
    "# adata.write_h5ad(os.path.join(data_dir,'hvg_dataset2_cellatlas.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA with n_comps = 50\n",
      "    finished (0:13:09.04)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:03:56.82) --> added to `.uns['neighbors']`\n",
      "    'distances', distances for each pair of neighbors\n",
      "    'connectivities', weighted adjacency matrix\n",
      "computing UMAP\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:20:50.68) --> added\n",
      "    'X_umap', UMAP coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata,n_neighbors=15, n_pcs=20)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'batch' as categorical\n"
     ]
    }
   ],
   "source": [
    "sc.pl.umap(adata, color=[\"batch\"], wspace=.3, show=False)\n",
    "save_images('dataset10_umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n",
      "    finished (0:57:57.27) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "color_group = [\"cell_type\",\"batch\"]\n",
    "plotTSNE(adata, color_group, 20, 90, base_name + '_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 19:36:56.125436 139810207172416 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:42: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0806 19:36:56.127121 139810207172416 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 19:36:59.182927 139810207172416 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0806 19:36:59.184667 139810207172416 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:78: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0806 19:36:59.185702 139810207172416 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:78: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0806 19:36:59.187080 139810207172416 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:79: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0806 19:36:59.432018 139810207172416 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:80: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0806 19:36:59.669781 139810207172416 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:82: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0806 19:36:59.816965 139810207172416 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:134: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0806 19:36:59.955747 139810207172416 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:177: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0806 19:37:01.036971 139810207172416 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:58: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Create a network\")\n",
    "t1 = time.time()\n",
    "# Initialize scGen with input is number of genes\n",
    "import scgen\n",
    "network = scgen.VAEArith(x_dimension=adata.shape[1], model_path=\"./results_cellatlas/batch_hvg\")\n",
    "# Need to check batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a network\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a network\")\n",
    "# Train scGen with nb epochs = 100\n",
    "# Requirement: adata should contain 2 vector: adata.obs[\"cell_type\"] and adata.obs[\"batch\"]\n",
    "network.train(train_data=adata, n_epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import anndata\n",
    "# Using trained model to correct, normalize data \n",
    "# Using batch removal function from scGen package \n",
    "\n",
    "#corrected_adata = scgen.batch_removal(network, total_ann)\n",
    "\n",
    "# In case this function does not work, replace batch_removal function by this function: batch_removal_v2\n",
    "# Hoa Tran\n",
    "def batch_removal_v2(network, adata):\n",
    "    if sparse.issparse(adata.X):\n",
    "        latent_all = network.to_latent(adata.X.A)\n",
    "    else:\n",
    "        latent_all = network.to_latent(adata.X)\n",
    "    adata_latent = anndata.AnnData(latent_all)\n",
    "    adata_latent.obs[\"cell_type\"] = adata.obs[\"cell_type\"].tolist()\n",
    "    adata_latent.obs[\"batch\"] = adata.obs[\"batch\"].tolist()\n",
    "    adata_latent.obs[\"cell_name\"] = adata.obs[\"cell_name\"].tolist()   #Hoa keep cell name infos\n",
    "    unique_cell_types = np.unique(adata_latent.obs[\"cell_type\"])\n",
    "    shared_ct = []\n",
    "    not_shared_ct = []\n",
    "    for cell_type in unique_cell_types:\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        if len(np.unique(temp_cell.obs[\"batch\"])) < 2:\n",
    "            cell_type_ann = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "            not_shared_ct.append(cell_type_ann)\n",
    "            continue\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        batch_list = {}\n",
    "        batch_ind = {}\n",
    "        max_batch = 0\n",
    "        max_batch_ind = \"\"\n",
    "        batches = np.unique(temp_cell.obs[\"batch\"])\n",
    "        for i in batches:\n",
    "            temp = temp_cell[temp_cell.obs[\"batch\"] == i]\n",
    "            temp_ind = temp_cell.obs[\"batch\"] == i\n",
    "            if max_batch < len(temp):\n",
    "                max_batch = len(temp)\n",
    "                max_batch_ind = i\n",
    "            batch_list[i] = temp\n",
    "            batch_ind[i] = temp_ind\n",
    "        max_batch_ann = batch_list[max_batch_ind]\n",
    "        for study in batch_list:\n",
    "            delta = np.average(max_batch_ann.X, axis=0) - np.average(batch_list[study].X, axis=0)\n",
    "            batch_list[study].X = delta + batch_list[study].X\n",
    "            temp_cell[batch_ind[study]].X = batch_list[study].X\n",
    "        shared_ct.append(temp_cell)\n",
    "    all_shared_ann = anndata.AnnData.concatenate(*shared_ct, batch_key=\"concat_batch\")\n",
    "    del all_shared_ann.obs[\"concat_batch\"]\n",
    "    if len(not_shared_ct) < 1:\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_shared_ann.X, use_data=True))\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected\n",
    "    else:\n",
    "        all_not_shared_ann = anndata.AnnData.concatenate(*not_shared_ct, batch_key=\"concat_batch\")\n",
    "        all_corrected_data = anndata.AnnData.concatenate(all_shared_ann, all_not_shared_ann, batch_key=\"concat_batch\")\n",
    "        del all_corrected_data.obs[\"concat_batch\"]\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_corrected_data.X, use_data=True), )\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist() + all_not_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_name\"].tolist()     #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correct data\")\n",
    "# Correct data using batch_removal function\n",
    "# Input: adata and network model \n",
    "adata.obs['cell_name'] = adata.obs_names\n",
    "adata.obs['batch']=adata.obs['batch'].astype('category')\n",
    "corrected_adata = batch_removal_v2(network, adata)\n",
    "t2 = time.time()\n",
    "print('Took '+str(timedelta(seconds=t2-t1)))\n",
    "# corrected_adata = scgen.batch_removal(network, adata1)\n",
    "# For verification\n",
    "# print(corrected_adata.obs['cell_name'][350:400])\n",
    "# print(corrected_adata.obs['cell_type'][350:400])\n",
    "corrected_adata.obs_names[1:10]\n",
    "print(corrected_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "time_taken = t2 - t1\n",
    "time_taken_mins = divmod(time_taken, 60)\n",
    "time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "hours_mins, hours_secs = divmod( rest, 60)\n",
    "print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "print('Took minutes: '+str(time_taken_mins))\n",
    "print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "usecase_name = 'scGen'\n",
    "filename = 'hvg_scGen_exetime.csv'\n",
    "\n",
    "data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "       'exetimehours': str(time_taken_hours),\n",
    "       'exetimemins': str(hours_mins),\n",
    "       'exetimesecs':str(round(hours_secs))} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['exetime'])\n",
    "print(df)\n",
    "df.to_csv(base_name + \"_exetime.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(corrected_adata, svd_solver='arpack', n_comps=20)\n",
    "corrected_adata.obsm['X_pca'] *= -1 # multiply by -1 to match Seurat, same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTSNE(corrected_adata, color_group, 20, 90, base_name + '_scgene_corrected_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write_csvs(base_name + \"_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_adata.write_csvs(base_name + \"_corrected_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
