{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scgen\n",
    "# Import package \n",
    "# Main using package here is scanpy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import scgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset10_hematoMNN_Hoa\n"
     ]
    }
   ],
   "source": [
    "base_name = os.path.basename(os.getcwd())\n",
    "print(base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n",
      "scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 \n"
     ]
    }
   ],
   "source": [
    "print(sc.__version__)\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "# sc.settings.set_figure_params(dpi=300, frameon=False)  # low dpi (dots per inch) yields small inline figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base_name, dpi=300, fig_type = \".png\"):\n",
    "    output_dir = os.path.dirname(base_name)\n",
    "    if not output_dir==\"\" and os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    fn, fe = os.path.splitext(base_name)\n",
    "    if(fe == \"\"):\n",
    "        base_name = base_name + fig_type\n",
    "    pl.savefig(base_name, dpi=dpi)\n",
    "    pl.close()\n",
    "    \n",
    "def plotTSNE(adata, color_group, n_pcs=20, perplexity=30, save_filename='tsne', use_repx = False):\n",
    "    #adata.var_names_make_unique()\n",
    "    random.seed(42)\n",
    "    if use_repx:\n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, use_rep='X')\n",
    "    else:    \n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, n_jobs=20)\n",
    "    sc.pl.tsne(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename) \n",
    "    \n",
    "def plotUMAP(adata, color_group, save_filename, use_repx = False):\n",
    "    \n",
    "#     if use_repx:\n",
    "#         sc.pp.neighbors(adata, use_rep='X')\n",
    "#     else:    \n",
    "#         sc.pp.neighbors(adata,n_neighbors=10, n_pcs=20)\n",
    "        \n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 4649 × 3467 \n",
      "Index(['W31106', 'W31107', 'W31108'], dtype='object')\n",
      "Index(['ENSMUSG00000000171', 'ENSMUSG00000000290', 'ENSMUSG00000000594'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read data from read count text table, data from R: genes x cells\n",
    "expression_data = '../../dataset/dataset10_hematoMNN_Hoa/dataset10_hematoMNN_Hoa_all_batch_rc_transpose_log.txt'\n",
    "adata = sc.read_text(expression_data, delimiter='\\t', first_column_names=True, dtype='float64')\n",
    "print(adata)  # 6954 x 1328\n",
    "print(adata.obs_names[0:3])\n",
    "print(adata.var_names[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4649, 2)\n",
      "Index(['cell_type', 'batch'], dtype='object')\n",
      "Index(['W31106', 'W31107', 'W31108', 'W31109', 'W31110', 'W31111', 'W31113',\n",
      "       'W31114', 'W31115', 'W31116',\n",
      "       ...\n",
      "       'Prog_851', 'Prog_809', 'Prog_816', 'Prog_822', 'Prog_828', 'Prog_834',\n",
      "       'Prog_840', 'Prog_846', 'Prog_852', 'Prog_810'],\n",
      "      dtype='object', length=4649)\n"
     ]
    }
   ],
   "source": [
    "# Read sample into a pandas series\n",
    "cell_info = \"../../dataset/dataset10_hematoMNN_Hoa/dataset10_hematoMNN_Hoa_all_cell_anno.txt\"\n",
    "sample_adata = pd.read_csv(cell_info,header=0, index_col=0, sep='\\t')\n",
    "print(sample_adata.values.shape)\n",
    "print(sample_adata.keys())\n",
    "print(sample_adata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4649\n",
      "4649\n"
     ]
    }
   ],
   "source": [
    "adata.obs['batch'] = sample_adata.loc[adata.obs_names, \"batch\"]\n",
    "print(len(adata.obs['batch']))\n",
    "adata.obs['cell_type'] = sample_adata.loc[adata.obs_names, \"cell_type\"]\n",
    "print(len(adata.obs['cell_type']))\n",
    "\n",
    "# Save output into h5ad, easy to access \n",
    "# adata.write_h5ad(os.path.join(data_dir,'hvg_dataset2_cellatlas.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA with n_comps = 50\n",
      "    finished (0:00:01.69)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:00:00.77) --> added to `.uns['neighbors']`\n",
      "    'distances', distances for each pair of neighbors\n",
      "    'connectivities', weighted adjacency matrix\n",
      "computing UMAP\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:00:16.81) --> added\n",
      "    'X_umap', UMAP coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata,n_neighbors=15, n_pcs=20)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n"
     ]
    }
   ],
   "source": [
    "sc.pl.umap(adata, color=[\"batch\"], wspace=.3, show=False)\n",
    "save_images('dataset10_umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n",
      "    finished (0:00:13.80) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "color_group = [\"cell_type\",\"batch\"]\n",
    "plotTSNE(adata, color_group, 20, 90, base_name + '_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a network\n"
     ]
    }
   ],
   "source": [
    "print(\"Create a network\")\n",
    "t1 = time.time()\n",
    "# Initialize scGen with input is number of genes\n",
    "import scgen\n",
    "network = scgen.VAEArith(x_dimension=adata.shape[1], model_path=\"./results_cellatlas/batch_hvg\")\n",
    "# Need to check batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a network\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a network\")\n",
    "# Train scGen with nb epochs = 100\n",
    "# Requirement: adata should contain 2 vector: adata.obs[\"cell_type\"] and adata.obs[\"batch\"]\n",
    "network.train(train_data=adata, n_epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import anndata\n",
    "# Using trained model to correct, normalize data \n",
    "# Using batch removal function from scGen package \n",
    "\n",
    "#corrected_adata = scgen.batch_removal(network, total_ann)\n",
    "\n",
    "# In case this function does not work, replace batch_removal function by this function: batch_removal_v2\n",
    "# Hoa Tran\n",
    "def batch_removal_v2(network, adata):\n",
    "    if sparse.issparse(adata.X):\n",
    "        latent_all = network.to_latent(adata.X.A)\n",
    "    else:\n",
    "        latent_all = network.to_latent(adata.X)\n",
    "    adata_latent = anndata.AnnData(latent_all)\n",
    "    adata_latent.obs[\"cell_type\"] = adata.obs[\"cell_type\"].tolist()\n",
    "    adata_latent.obs[\"batch\"] = adata.obs[\"batch\"].tolist()\n",
    "    adata_latent.obs[\"cell_name\"] = adata.obs[\"cell_name\"].tolist()   #Hoa keep cell name infos\n",
    "    unique_cell_types = np.unique(adata_latent.obs[\"cell_type\"])\n",
    "    shared_ct = []\n",
    "    not_shared_ct = []\n",
    "    for cell_type in unique_cell_types:\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        if len(np.unique(temp_cell.obs[\"batch\"])) < 2:\n",
    "            cell_type_ann = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "            not_shared_ct.append(cell_type_ann)\n",
    "            continue\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        batch_list = {}\n",
    "        batch_ind = {}\n",
    "        max_batch = 0\n",
    "        max_batch_ind = \"\"\n",
    "        batches = np.unique(temp_cell.obs[\"batch\"])\n",
    "        for i in batches:\n",
    "            temp = temp_cell[temp_cell.obs[\"batch\"] == i]\n",
    "            temp_ind = temp_cell.obs[\"batch\"] == i\n",
    "            if max_batch < len(temp):\n",
    "                max_batch = len(temp)\n",
    "                max_batch_ind = i\n",
    "            batch_list[i] = temp\n",
    "            batch_ind[i] = temp_ind\n",
    "        max_batch_ann = batch_list[max_batch_ind]\n",
    "        for study in batch_list:\n",
    "            delta = np.average(max_batch_ann.X, axis=0) - np.average(batch_list[study].X, axis=0)\n",
    "            batch_list[study].X = delta + batch_list[study].X\n",
    "            temp_cell[batch_ind[study]].X = batch_list[study].X\n",
    "        shared_ct.append(temp_cell)\n",
    "    all_shared_ann = anndata.AnnData.concatenate(*shared_ct, batch_key=\"concat_batch\")\n",
    "    del all_shared_ann.obs[\"concat_batch\"]\n",
    "    if len(not_shared_ct) < 1:\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_shared_ann.X, use_data=True))\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected\n",
    "    else:\n",
    "        all_not_shared_ann = anndata.AnnData.concatenate(*not_shared_ct, batch_key=\"concat_batch\")\n",
    "        all_corrected_data = anndata.AnnData.concatenate(all_shared_ann, all_not_shared_ann, batch_key=\"concat_batch\")\n",
    "        del all_corrected_data.obs[\"concat_batch\"]\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_corrected_data.X, use_data=True), )\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist() + all_not_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_name\"].tolist()     #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n",
      "Trying to set attribute `.X` of view, making a copy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 0:04:33.743745\n",
      "AnnData object with n_obs × n_vars = 4649 × 3467 \n",
      "    obs: 'cell_type', 'batch', 'cell_name'\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct data\")\n",
    "# Correct data using batch_removal function\n",
    "# Input: adata and network model \n",
    "adata.obs['cell_name'] = adata.obs_names\n",
    "adata.obs['batch']=adata.obs['batch'].astype('category')\n",
    "corrected_adata = batch_removal_v2(network, adata)\n",
    "t2 = time.time()\n",
    "print('Took '+str(timedelta(seconds=t2-t1)))\n",
    "# corrected_adata = scgen.batch_removal(network, adata1)\n",
    "# For verification\n",
    "# print(corrected_adata.obs['cell_name'][350:400])\n",
    "# print(corrected_adata.obs['cell_type'][350:400])\n",
    "corrected_adata.obs_names[1:10]\n",
    "print(corrected_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563430269.407627\n",
      "1563430543.1513717\n",
      "Took seconds: 0:04:34\n",
      "Took minutes: (4.0, 33.74374461174011)\n",
      "Took hours_minutes_seconds:  0.0 4.0 33.74374461174011\n",
      "        use_case exetime_secs exetimehours exetimemins exetimesecs\n",
      "exetime    scGen          274          0.0         4.0          34\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "time_taken = t2 - t1\n",
    "time_taken_mins = divmod(time_taken, 60)\n",
    "time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "hours_mins, hours_secs = divmod( rest, 60)\n",
    "print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "print('Took minutes: '+str(time_taken_mins))\n",
    "print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "usecase_name = 'scGen'\n",
    "filename = 'hvg_scGen_exetime.csv'\n",
    "\n",
    "data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "       'exetimehours': str(time_taken_hours),\n",
    "       'exetimemins': str(hours_mins),\n",
    "       'exetimesecs':str(round(hours_secs))} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['exetime'])\n",
    "print(df)\n",
    "df.to_csv(base_name + \"_exetime.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA with n_comps = 20\n",
      "    finished (0:00:00.26)\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(corrected_adata, svd_solver='arpack', n_comps=20)\n",
    "corrected_adata.obsm['X_pca'] *= -1 # multiply by -1 to match Seurat, same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n",
      "... storing 'batch' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:15.85) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "plotTSNE(corrected_adata, color_group, 20, 90, base_name + '_scgene_corrected_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing '.csv' files to dataset10_hematoMNN_Hoa_results\n"
     ]
    }
   ],
   "source": [
    "adata.write_csvs(base_name + \"_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing '.csv' files to dataset10_hematoMNN_Hoa_corrected_results\n"
     ]
    }
   ],
   "source": [
    "corrected_adata.write_csvs(base_name + \"_corrected_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
