{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scgen\n",
    "# Import package \n",
    "# Main using package here is scanpy \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import scanpy as sc\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import random\n",
    "import scgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1_uc3\n"
     ]
    }
   ],
   "source": [
    "base_name = os.path.basename(os.getcwd())\n",
    "print(base_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.3\n",
      "scanpy==1.4.3 anndata==0.6.21 umap==0.3.9 numpy==1.16.2 scipy==1.2.1 pandas==0.24.2 scikit-learn==0.20.3 statsmodels==0.9.0 \n"
     ]
    }
   ],
   "source": [
    "print(sc.__version__)\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()\n",
    "# sc.settings.set_figure_params(dpi=300, frameon=False)  # low dpi (dots per inch) yields small inline figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(base_name, dpi=300, fig_type = \".png\"):\n",
    "    output_dir = os.path.dirname(base_name)\n",
    "    if not output_dir==\"\" and os.path.exists(output_dir): os.makedirs(output_dir)\n",
    "    fn, fe = os.path.splitext(base_name)\n",
    "    if(fe == \"\"):\n",
    "        base_name = base_name + fig_type\n",
    "    pl.savefig(base_name, dpi=dpi)\n",
    "    pl.close()\n",
    "    \n",
    "def plotTSNE(adata, color_group, n_pcs=20, perplexity=30, save_filename='tsne', use_repx = False):\n",
    "    #adata.var_names_make_unique()\n",
    "    random.seed(42)\n",
    "    if use_repx:\n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, use_rep='X')\n",
    "    else:    \n",
    "        sc.tl.tsne(adata, random_state=0, n_pcs=n_pcs, perplexity=perplexity, n_jobs=20)\n",
    "    sc.pl.tsne(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename) \n",
    "    \n",
    "def plotUMAP(adata, color_group, save_filename, use_repx = False):\n",
    "    \n",
    "#     if use_repx:\n",
    "#         sc.pp.neighbors(adata, use_rep='X')\n",
    "#     else:    \n",
    "#         sc.pp.neighbors(adata,n_neighbors=10, n_pcs=20)\n",
    "        \n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color = color_group, show=False, wspace=.4)\n",
    "    save_images(save_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 26593 × 576 \n",
      "Index(['1/2-SBSRNA4', '5S_RRNA', '5_8S_RRNA'], dtype='object')\n",
      "Index(['pDC_P10_S73', 'pDC_P10_S74', 'pDC_P10_S75'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read data from read count text table, data from R: genes x cells\n",
    "expression_data = './dataset1_sm_uc3.txt'\n",
    "adata = sc.read_text(expression_data, delimiter='\\t', first_column_names=True, dtype='float64')\n",
    "print(adata)  # 6954 x 1328\n",
    "print(adata.obs_names[0:3])\n",
    "print(adata.var_names[0:3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pDC_P10_S73', 'pDC_P10_S74', 'pDC_P10_S75'], dtype='object')\n",
      "Index(['1/2-SBSRNA4', '5S_RRNA', '5_8S_RRNA'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "adata = adata.transpose()\n",
    "sc.pp.normalize_per_cell(adata)\n",
    "sc.pp.log1p(adata)\n",
    "print(adata.obs_names[0:3])\n",
    "print(adata.var_names[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 4)\n",
      "Index(['cell', 'celltype', 'batch', 'cell_type'], dtype='object')\n",
      "Index(['pDC_P10_S73', 'pDC_P10_S74', 'pDC_P10_S75', 'pDC_P10_S76',\n",
      "       'pDC_P10_S77', 'pDC_P10_S78', 'pDC_P10_S79', 'pDC_P10_S80',\n",
      "       'pDC_P10_S81', 'pDC_P10_S82',\n",
      "       ...\n",
      "       'CD1C_P4_S39', 'CD1C_P4_S40', 'CD1C_P4_S41', 'CD1C_P4_S42',\n",
      "       'CD1C_P4_S43', 'CD1C_P4_S44', 'CD1C_P4_S45', 'CD1C_P4_S46',\n",
      "       'CD1C_P4_S47', 'CD1C_P4_S48'],\n",
      "      dtype='object', length=576)\n"
     ]
    }
   ],
   "source": [
    "# Read sample into a pandas series\n",
    "cell_info = \"./sample_sm_uc3.txt\"\n",
    "sample_adata = pd.read_csv(cell_info,header=0, index_col=0, sep='\\t')\n",
    "print(sample_adata.values.shape)\n",
    "print(sample_adata.keys())\n",
    "print(sample_adata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "576\n"
     ]
    }
   ],
   "source": [
    "adata.obs['batch'] = sample_adata.loc[adata.obs_names, \"batch\"]\n",
    "print(len(adata.obs['batch']))\n",
    "adata.obs['cell_type'] = sample_adata.loc[adata.obs_names, \"cell_type\"]\n",
    "print(len(adata.obs['cell_type']))\n",
    "# Save output into h5ad, easy to access \n",
    "# adata.write_h5ad(os.path.join(data_dir,'hvg_dataset2_cellatlas.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA with n_comps = 50\n",
      "    finished (0:00:01.63)\n",
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:00:01.69) --> added to `.uns['neighbors']`\n",
      "    'distances', distances for each pair of neighbors\n",
      "    'connectivities', weighted adjacency matrix\n",
      "computing UMAP\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:00:02.73) --> added\n",
      "    'X_umap', UMAP coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pp.neighbors(adata,n_neighbors=15, n_pcs=20)\n",
    "sc.tl.umap(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'batch' as categorical\n",
      "... storing 'cell_type' as categorical\n"
     ]
    }
   ],
   "source": [
    "sc.pl.umap(adata, color=[\"batch\"], wspace=.3, show=False)\n",
    "save_images('dataset10_umap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n",
      "    finished (0:00:01.29) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "color_group = [\"cell_type\",\"batch\"]\n",
    "plotTSNE(adata, color_group, 20, 90, base_name + '_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 11:26:00.046996 139747363751744 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:42: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W0813 11:26:00.048668 139747363751744 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0813 11:26:02.773087 139747363751744 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0813 11:26:02.774823 139747363751744 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:78: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "W0813 11:26:02.775873 139747363751744 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:78: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n",
      "W0813 11:26:02.777230 139747363751744 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:79: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0813 11:26:03.013361 139747363751744 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:80: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0813 11:26:03.288598 139747363751744 deprecation.py:323] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:82: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0813 11:26:04.124071 139747363751744 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:134: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W0813 11:26:04.379254 139747363751744 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:177: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "W0813 11:26:05.226876 139747363751744 deprecation_wrapper.py:119] From /home/xm/.local/lib/python3.7/site-packages/scgen/models/_vae.py:58: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Create a network\")\n",
    "t1 = time.time()\n",
    "# Initialize scGen with input is number of genes\n",
    "import scgen\n",
    "network = scgen.VAEArith(x_dimension=adata.shape[1], model_path=\"./results_cellatlas/batch_hvg\")\n",
    "# Need to check batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train a network\n"
     ]
    }
   ],
   "source": [
    "print(\"Train a network\")\n",
    "# Train scGen with nb epochs = 100\n",
    "# Requirement: adata should contain 2 vector: adata.obs[\"cell_type\"] and adata.obs[\"batch\"]\n",
    "network.train(train_data=adata, n_epochs=100, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "import anndata\n",
    "# Using trained model to correct, normalize data \n",
    "# Using batch removal function from scGen package \n",
    "\n",
    "#corrected_adata = scgen.batch_removal(network, total_ann)\n",
    "\n",
    "# In case this function does not work, replace batch_removal function by this function: batch_removal_v2\n",
    "# Hoa Tran\n",
    "def batch_removal_v2(network, adata):\n",
    "    if sparse.issparse(adata.X):\n",
    "        latent_all = network.to_latent(adata.X.A)\n",
    "    else:\n",
    "        latent_all = network.to_latent(adata.X)\n",
    "    adata_latent = anndata.AnnData(latent_all)\n",
    "    adata_latent.obs[\"cell_type\"] = adata.obs[\"cell_type\"].tolist()\n",
    "    adata_latent.obs[\"batch\"] = adata.obs[\"batch\"].tolist()\n",
    "    adata_latent.obs[\"cell_name\"] = adata.obs[\"cell_name\"].tolist()   #Hoa keep cell name infos\n",
    "    unique_cell_types = np.unique(adata_latent.obs[\"cell_type\"])\n",
    "    shared_ct = []\n",
    "    not_shared_ct = []\n",
    "    print(unique_cell_types)\n",
    "    for cell_type in unique_cell_types:\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        if len(np.unique(temp_cell.obs[\"batch\"])) < 2:\n",
    "            cell_type_ann = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "            not_shared_ct.append(cell_type_ann)\n",
    "            continue\n",
    "        temp_cell = adata_latent[adata_latent.obs[\"cell_type\"] == cell_type]\n",
    "        batch_list = {}\n",
    "        batch_ind = {}\n",
    "        max_batch = 0\n",
    "        max_batch_ind = \"\"\n",
    "        batches = np.unique(temp_cell.obs[\"batch\"])\n",
    "        print(batches)\n",
    "        for i in batches:\n",
    "            temp = temp_cell[temp_cell.obs[\"batch\"] == i]\n",
    "            temp_ind = temp_cell.obs[\"batch\"] == i\n",
    "            if max_batch < len(temp):\n",
    "                max_batch = len(temp)\n",
    "                max_batch_ind = i\n",
    "            batch_list[i] = temp\n",
    "            batch_ind[i] = temp_ind\n",
    "        max_batch_ann = batch_list[max_batch_ind]\n",
    "        print(batch_list)\n",
    "        for study in batch_list:\n",
    "            delta = np.average(max_batch_ann.X, axis=0) - np.average(batch_list[study].X, axis=0)\n",
    "            batch_list[study].X = delta + batch_list[study].X\n",
    "            temp_cell[batch_ind[study]].X = batch_list[study].X\n",
    "        shared_ct.append(temp_cell)\n",
    "    print('shared_ct')\n",
    "    print(shared_ct)\n",
    "    print(len(shared_ct))\n",
    "    # if len(shared_ct) > 1:\n",
    "    all_shared_ann = anndata.AnnData.concatenate(*shared_ct, batch_key=\"concat_batch\")\n",
    "    # del all_shared_ann.obs[\"concat_batch\"]\n",
    "    if len(not_shared_ct) < 1:\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_shared_ann.X, use_data=True))\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected\n",
    "    else:\n",
    "        all_not_shared_ann = anndata.AnnData.concatenate(*not_shared_ct, batch_key=\"concat_batch\")\n",
    "        all_corrected_data = anndata.AnnData.concatenate(all_shared_ann, all_not_shared_ann, batch_key=\"concat_batch\")\n",
    "        del all_corrected_data.obs[\"concat_batch\"]\n",
    "        corrected = anndata.AnnData(network.reconstruct(all_corrected_data.X, use_data=True), )\n",
    "        corrected.obs[\"cell_type\"] = all_shared_ann.obs[\"cell_type\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_type\"].tolist()\n",
    "        corrected.obs[\"batch\"] = all_shared_ann.obs[\"batch\"].tolist() + all_not_shared_ann.obs[\"batch\"].tolist()\n",
    "        corrected.obs[\"cell_name\"] = all_shared_ann.obs[\"cell_name\"].tolist() + all_not_shared_ann.obs[\n",
    "            \"cell_name\"].tolist()     #Hoa keep cell name infos\n",
    "        corrected.var_names = adata.var_names.tolist()\n",
    "        corrected.obs_names = corrected.obs['cell_name'] #Hoa assign cell name infos\n",
    "        return corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.X` of view, making a copy.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct data\n",
      "['undefined']\n",
      "['Batch1' 'Batch2']\n",
      "{'Batch1': View of AnnData object with n_obs × n_vars = 288 × 100 \n",
      "    obs: 'cell_type', 'batch', 'cell_name', 'Batch2': View of AnnData object with n_obs × n_vars = 288 × 100 \n",
      "    obs: 'cell_type', 'batch', 'cell_name'}\n",
      "shared_ct\n",
      "[AnnData object with n_obs × n_vars = 576 × 100 \n",
      "    obs: 'cell_type', 'batch', 'cell_name']\n",
      "1\n",
      "Took 0:21:26.997227\n",
      "AnnData object with n_obs × n_vars = 576 × 26593 \n",
      "    obs: 'cell_type', 'batch', 'cell_name'\n"
     ]
    }
   ],
   "source": [
    "print(\"Correct data\")\n",
    "# Correct data using batch_removal function\n",
    "# Input: adata and network model \n",
    "adata.obs['cell_name'] = adata.obs_names\n",
    "adata.obs['batch']=adata.obs['batch'].astype('category')\n",
    "corrected_adata = batch_removal_v2(network, adata)\n",
    "t2 = time.time()\n",
    "print('Took '+str(timedelta(seconds=t2-t1)))\n",
    "# corrected_adata = scgen.batch_removal(network, adata1)\n",
    "# For verification\n",
    "# print(corrected_adata.obs['cell_name'][350:400])\n",
    "# print(corrected_adata.obs['cell_type'][350:400])\n",
    "corrected_adata.obs_names[1:10]\n",
    "print(corrected_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1565666760.0468493\n",
      "1565668047.0440764\n",
      "Took seconds: 0:21:27\n",
      "Took minutes: (21.0, 26.99722719192505)\n",
      "Took hours_minutes_seconds:  0.0 21.0 26.99722719192505\n",
      "        use_case exetime_secs exetimehours exetimemins exetimesecs\n",
      "exetime    scGen         1287          0.0        21.0          27\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t2)\n",
    "time_taken = t2 - t1\n",
    "time_taken_mins = divmod(time_taken, 60)\n",
    "time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "hours_mins, hours_secs = divmod( rest, 60)\n",
    "print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "print('Took minutes: '+str(time_taken_mins))\n",
    "print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "usecase_name = 'scGen'\n",
    "filename = 'hvg_scGen_exetime.csv'\n",
    "\n",
    "data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "       'exetimehours': str(time_taken_hours),\n",
    "       'exetimemins': str(hours_mins),\n",
    "       'exetimesecs':str(round(hours_secs))} \n",
    "  \n",
    "# Creates pandas DataFrame. \n",
    "df = pd.DataFrame(data, index =['exetime'])\n",
    "print(df)\n",
    "df.to_csv(base_name + \"_exetime.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing PCA with n_comps = 20\n",
      "    finished (0:00:00.33)\n"
     ]
    }
   ],
   "source": [
    "sc.tl.pca(corrected_adata, svd_solver='arpack', n_comps=20)\n",
    "corrected_adata.obsm['X_pca'] *= -1 # multiply by -1 to match Seurat, same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n",
      "... storing 'batch' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:01.24) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "plotTSNE(corrected_adata, color_group, 20, 90, base_name + '_scgene_corrected_tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing '.csv' files to dataset1_uc3_results\n"
     ]
    }
   ],
   "source": [
    "adata.write_csvs(base_name + \"_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "writing '.csv' files to dataset1_uc3_corrected_results\n"
     ]
    }
   ],
   "source": [
    "corrected_adata.write_csvs(base_name + \"_corrected_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
