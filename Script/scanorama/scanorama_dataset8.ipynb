{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ample\n",
    "# import scanorama\n",
    "# import pkg_resources\n",
    "# pkg_resources.get_distribution(\"scanorama\").version\n",
    "# !pip show scanorama\n",
    "# ??scanorama.correct\n",
    "#  When `return_dimred=False`, returns a two-tuple containing a list of\n",
    "#         `np.ndarray` with integrated low-dimensional embeddings and a list\n",
    "#         of `scanpy.api.AnnData` with batch corrected values in the `.X`\n",
    "#         field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.4+18.gaabe446 anndata==0.6.17 numpy==1.15.4 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 \n"
     ]
    }
   ],
   "source": [
    "# Scanorama batch effect correction\n",
    "# See more at: https://github.com/brianhie/scanorama\n",
    "# Hoa Tran \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/acrc/jinmiao/CJM_lab/hoatran/demo_normalization/demo_Scanorama/scanorama_python\n",
      "/acrc/jinmiao/CJM_lab/hoatran/demo_normalization/demo_Scanorama/scanorama_python/results/result_dataset8_mouse_brain/\n"
     ]
    }
   ],
   "source": [
    "# Create folder to save the results \n",
    "import os\n",
    "dirname = os.getcwd()\n",
    "print(dirname)\n",
    "\n",
    "\n",
    "if not os.path.exists('./results/'): os.makedirs('./results/')   \n",
    "if not os.path.exists('./results/result_dataset8_mouse_brain/'): os.makedirs('./results/result_dataset8_mouse_brain/')    \n",
    "save_dir = os.path.join(dirname, 'results/result_dataset8_mouse_brain/')\n",
    "print(save_dir)\n",
    "\n",
    "# Function to save figure as image in the figures folder\n",
    "save_fig_dir='./figures/dataset8_mouse_brain/'\n",
    "if not os.path.exists('./figures/'): os.makedirs('./figures/')\n",
    "if not os.path.exists(save_fig_dir): os.makedirs(save_fig_dir)\n",
    "def save_images(filename, save_fig_dir):    \n",
    "    outname = save_fig_dir + filename + '.png'\n",
    "    pl.savefig(outname, dpi=150)\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 833206 × 17745 \n",
       "    obs: 'cell_type', 'batch'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Read data')\n",
    "data_dir = os.path.join('/acrc/jinmiao/CJM_lab/hoatran/demo_normalization/dataset/dataset8_Mouse_brain/raw_data_python/')\n",
    "savefn = 'dataset8.h5ad'\n",
    "adata = sc.read_h5ad(os.path.join(data_dir,savefn))\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_dir = '/acrc/jinmiao/CJM_lab/hoatran/demo_normalization/xiaomeng/generate_PCA_tSNE_UMAP/dataset8/'\n",
    "# myDatafn = 'dataset8_raw_pca.csv'\n",
    "# myPCADS = pd.read_csv(os.path.join(ds_dir, myDatafn),header=0, index_col=0)\n",
    "# print(myPCADS.values.shape)\n",
    "# print(myPCADS.keys())\n",
    "# print(myPCADS.index[1:5])\n",
    "# adata.X[1:3,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 833206 × 17745 \n",
       "    obs: 'cell_type', 'batch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 83323 × 17745 \n",
       "    obs: 'cell_type', 'batch', 'n_counts'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Read data')\n",
    "data_dir = '/acrc/jinmiao/CJM_lab/hoatran/demo_normalization/dataset/dataset8_Mouse_brain/raw_data_python/'\n",
    "savefnds = 'downsample_d8_10percent.h5ad'\n",
    "adatads = sc.read_h5ad(os.path.join(data_dir,savefnds))\n",
    "sc.pp.normalize_per_cell(adatads)\n",
    "sc.pp.log1p(adatads)\n",
    "adatads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> added\n",
      "    'highly_variable', boolean vector (adata.var)\n",
      "    'means', float vector (adata.var)\n",
      "    'dispersions', float vector (adata.var)\n",
      "    'dispersions_norm', float vector (adata.var)\n",
      "[5000, 17745]\n"
     ]
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(adatads, n_top_genes=5000, flavor='seurat')\n",
    "print([sum(adatads.var['highly_variable']),len(adatads.var['highly_variable'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View of AnnData object with n_obs × n_vars = 691600 × 5000 \n",
      "    obs: 'cell_type', 'batch', 'n_counts'\n",
      "View of AnnData object with n_obs × n_vars = 141606 × 5000 \n",
      "    obs: 'cell_type', 'batch', 'n_counts'\n"
     ]
    }
   ],
   "source": [
    "# Extract data from batch 1 and batch 2\n",
    "# Already filtered\n",
    "# sc.pp.filter_cells(adata, min_genes=300)\n",
    "# sc.pp.filter_genes(adata, min_cells=10)\n",
    "\n",
    "sc.pp.normalize_per_cell(adata)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "adata1 = adata[adata.obs['batch']=='batch1',:].copy()\n",
    "adata1 = adata1[:,adatads.var['highly_variable']]\n",
    "adata2 = adata[adata.obs['batch']=='batch2',:].copy()\n",
    "adata2 = adata2[:,adatads.var['highly_variable']]\n",
    "print(adata1)\n",
    "print(adata2)\n",
    "# sum(adata2.var_names==adata1.var_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 141606 × 5000 \n",
       "    obs: 'cell_type', 'batch', 'n_counts'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanorama import correct, visualize, process_data\n",
    "from scanorama import dimensionality_reduce\n",
    "from scanorama import *\n",
    "import scanorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_data(datasets, genes, hvg=HVG, dimred=DIMRED, verbose=False)\n",
    "# datasets_dimred, genes = process_data(datasets, genes, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  corrected, corrected_be = scanorama.correct_scanpy(adata_ls, batch_size=80, \n",
    "#                                                       return_dimred=True, geosketch=True, geosketch_max=6900)\n",
    "# from ample import gs, uniform\n",
    "# Can not work \n",
    "# !pip install scanorama --upgrade\n",
    "\n",
    "adata_ls = [adata1, adata2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 genes among all datasets\n",
      "[[0.         0.16884058]\n",
      " [0.         0.        ]]\n",
      "Processing datasets (0, 1)\n",
      "Took 0:11:57.010815\n"
     ]
    }
   ],
   "source": [
    "# integrated, corrected\n",
    "# When `return_dimred=True`, returns a two-tuple containing a list of\n",
    "# `np.ndarray` with integrated low-dimensional embeddings and a list\n",
    "# of new `scanpy.api.AnnData`.\n",
    "\n",
    "# Batch correction.\n",
    "# datasets = [df.values]\n",
    "# List of datasets (matrices of cells-by-genes)\n",
    "t1 = time.time()\n",
    "# corrected = scanorama.correct_scanpy(adata_ls, batch_size=60, return_dense=True, knn=15)\n",
    "# corrected, genes = scanorama.correct(adata_ls, adata1.var_names,batch_size=30)\n",
    "corrected, corrected_be = scanorama.correct_scanpy(adata_ls, batch_size=80, \n",
    "                                                   return_dimred=True,\n",
    "                                                   geosketch=True, geosketch_max=6900)\n",
    "\n",
    "# integrated, corrected = scanorama.correct_scanpy(adatas, return_dimred=True)\n",
    "t2 = time.time()\n",
    "print('Took '+str(timedelta(seconds=t2-t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 691600 × 5000 \n",
      "AnnData object with n_obs × n_vars = 141606 × 5000 \n"
     ]
    }
   ],
   "source": [
    "print(corrected_be[0])\n",
    "print(corrected_be[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took seconds: 0:11:57\n",
      "Took minutes: (11.0, 57.01081466674805)\n",
      "Took hours_minutes_seconds:  0.0 11.0 57.01081466674805\n",
      "                  use_case exetime_secs exetimehours exetimemins exetimesecs\n",
      "exetime  scanorama_exetime          717          0.0        11.0          57\n",
      "/acrc/jinmiao/CJM_lab/hoatran/demo_normalization/demo_Scanorama/scanorama_python/results/result_dataset8_mouse_brain/\n"
     ]
    }
   ],
   "source": [
    "def getExecutionTime(t1, t2, save_dir, usecase_name,filename):\n",
    "    time_taken = (t2 - t1)\n",
    "    time_taken_mins = divmod(time_taken, 60)\n",
    "    time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "    hours_mins, hours_secs = divmod( rest, 60)\n",
    "    print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "    print('Took minutes: '+str(time_taken_mins))\n",
    "    print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "    \n",
    "    \n",
    "\n",
    "    data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "           'exetimehours': str(time_taken_hours),\n",
    "           'exetimemins': str(hours_mins),\n",
    "           'exetimesecs':str(round(hours_secs))} \n",
    "    df = pd.DataFrame(data, index =['exetime'])\n",
    "    print(df)\n",
    "    df.to_csv(save_dir+filename) \n",
    "\n",
    "# Evaluation runtime of main batch effect removal function\n",
    "filename = 'scanorama_exetime.csv'\n",
    "usecase_name = 'scanorama_exetime' \n",
    "getExecutionTime(t1, t2, save_dir, usecase_name, filename)  # t1: start time, t2: end time  \n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del adata_ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_adata = corrected_be[0].concatenate(corrected_be[1])\n",
    "# print(sum(adata1.obs_names[1:3]==corrected_be[0].obs_names[1:3]))\n",
    "# print(adata1.X.shape)\n",
    "corrected_adata.var_names = corrected_be[0].var_names.tolist()\n",
    "corrected_adata.obs_names = adata1.obs_names.tolist() + adata2.obs_names.tolist() \n",
    "corrected_adata.obs['cell_type'] = adata1.obs['cell_type'].tolist() + adata2.obs['cell_type'].tolist() \n",
    "corrected_adata.obs['batch'] = adata1.obs['batch'].tolist() + adata2.obs['batch'].tolist() \n",
    "\n",
    "# corrected_adata.obs_names = adata1.obs_names.tolist() + adata2.obs_names.tolist() \n",
    "# corrected_adata.obs['cell_type'] = adata1.obs['cell_type'].tolist() + adata2.obs['cell_type'].tolist() \n",
    "# corrected_adata.obs['batch'] = adata1.obs['batch'].tolist() + adata2.obs['batch'].tolist() \n",
    "\n",
    "corrected_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(adatads.obs['batch']=='batch2')\n",
    "\n",
    "adata_ds = corrected_adata[adatads.obs_names,:].copy()\n",
    "print(adata_ds)\n",
    "\n",
    "npcs = 20  \n",
    "sc.tl.pca(adata_ds, svd_solver='arpack', n_comps=npcs)  \n",
    "adata_ds.obsm['X_pca'] *= -1  # multiply by -1 to match Seurat\n",
    "adata_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output_pca(adata, save_dir): \n",
    "    # Save output of pca for evaluation ASW\n",
    "    colnpc = []\n",
    "    for i in range(20):\n",
    "        colnpc.append(\"X_pca\"+str(i+1))\n",
    "\n",
    "    df = pd.DataFrame(adata.obsm['X_pca'][:, :20], columns=colnpc, index=adata.obs_names)\n",
    "    df['batch'] = pd.Series(adata.obs['batch'], index=adata.obs_names)\n",
    "#     df['batchlb'] = pd.Series(adata.obs['batchlb'], index=adata.obs_names)\n",
    "    df['celltype'] = pd.Series(adata.obs['cell_type'], index=adata.obs_names)\n",
    "    df.to_csv(save_dir+'scanorama_pca.csv')\n",
    "    \n",
    "save_output_pca(adata_ds, save_dir)\n",
    "print('Save output of normalized pca in :',save_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def downsampling(cells_batches, percentds=0.1):\n",
    "#     cells_ext = []\n",
    "#     for i in range(len(cells_batches)):\n",
    "#         rand_cidx = np.random.choice(cells_batches[i],size=int(len(cells_batches[i])*percentds),replace=False)\n",
    "#         print('Extract cells from batch{}:  {} '.format(i+1,len(rand_cidx)))\n",
    "#         cells_ext.append(rand_cidx)\n",
    "        \n",
    "#     return cells_ext    \n",
    "        \n",
    "\n",
    "# cells_batches = []\n",
    "# # cells_batches.append(corrected_be[0].obs_names)\n",
    "# # cells_batches.append(corrected_be[1].obs_names)\n",
    "\n",
    "# cells_batches.append(adata1.obs_names)\n",
    "# cells_batches.append(adata2.obs_names)\n",
    "    \n",
    "# cells_ext = downsampling(cells_batches, 0.1)\n",
    "\n",
    "# cells_ext = np.concatenate(cells_ext)\n",
    "# adata_ds = corrected_adata[cells_ext,:].copy()\n",
    "# adata_ds    \n",
    "\n",
    "# npcs = 20  \n",
    "# sc.tl.pca(adata_ds, svd_solver='arpack', n_comps=npcs)  \n",
    "# adata_ds.obsm['X_pca'] *= -1  # multiply by -1 to match Seurat\n",
    "# adata_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotUMAP(adata, color_group, save_filename='umap', save_dir='', npcs=20, nb_neighbors=15, use_repx = False):\n",
    "    \n",
    "    # Run with all genes and entire expr matrix\n",
    "    if use_repx:\n",
    "        sc.pp.neighbors(adata, use_rep='X')\n",
    "    else:    # Run umap using pcs vectors\n",
    "        sc.pp.neighbors(adata,n_neighbors=nb_neighbors, n_pcs=npcs)\n",
    "        \n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color = color_group, show=False)\n",
    "    save_images(save_filename, save_dir)\n",
    "\n",
    "    \n",
    "npcs = 20  # our pre-defined\n",
    "perplex = 30  # our pre-defined\n",
    "nb_neighbors = 15\n",
    "color_group = ['batch','cell_type'] \n",
    "save_fn_umap = 'scanorama_umap_ds_10percent_kokds'\n",
    "print(save_fig_dir)\n",
    "plotUMAP(adata_ds, color_group, save_fn_umap, save_fig_dir, npcs, nb_neighbors, False)\n",
    "print('Save output of UMAP figure in :',save_fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getExecutionTime(t1, t2, save_dir, usecase_name,filename):\n",
    "    time_taken = (t2 - t1)\n",
    "    time_taken_mins = divmod(time_taken, 60)\n",
    "    time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "    hours_mins, hours_secs = divmod( rest, 60)\n",
    "    print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "    print('Took minutes: '+str(time_taken_mins))\n",
    "    print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "    \n",
    "    \n",
    "\n",
    "    data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "           'exetimehours': str(time_taken_hours),\n",
    "           'exetimemins': str(hours_mins),\n",
    "           'exetimesecs':str(round(hours_secs))} \n",
    "    df = pd.DataFrame(data, index =['exetime'])\n",
    "    print(df)\n",
    "    df.to_csv(save_dir+filename) \n",
    "\n",
    "# Evaluation runtime of main batch effect removal function\n",
    "filename = 'scanorama_exetime.csv'\n",
    "usecase_name = 'scanorama_exetime' \n",
    "getExecutionTime(t1, t2, save_dir, usecase_name, filename)  # t1: start time, t2: end time  \n",
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output_umap(adata, save_dir): \n",
    "    colnu = []\n",
    "    for i in range(adata.obsm['X_umap'].shape[1]):\n",
    "        colnu.append(\"UMAP\"+str(i+1))\n",
    "    df = pd.DataFrame(adata.obsm['X_umap'], columns=colnu, index=adata.obs_names)\n",
    "    df['batch'] = pd.Series(adata.obs['batch'], index=adata.obs_names)\n",
    "#     df['batchlb'] = pd.Series(adata.obs['batchlb'], index=adata.obs_names)\n",
    "    df['cell_type'] = pd.Series(adata.obs['cell_type'], index=adata.obs_names)\n",
    "    df.to_csv(save_dir+'scanorama_umap.csv')  \n",
    "\n",
    "    \n",
    "# Apply to our data    \n",
    "save_output_umap(adata_ds, save_dir)\n",
    "print('Save output of normalized data in :',save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to plot TSNE\n",
    "def plotTSNE(adata, color_group, save_filename='tsne', save_dir='', n_pcs=20, perplex=30, use_repx = False):\n",
    "    \n",
    "    # Run with all genes and entire matrix\n",
    "    if use_repx:\n",
    "        sc.tl.tsne(adata, perplexity=perplex, use_rep='X')\n",
    "    else:    # Run tsne using pcs vectors\n",
    "        sc.tl.tsne(adata, n_pcs=n_pcs, perplexity=perplex)\n",
    "    sc.pl.tsne(adata, color = color_group, show=False, wspace=.3)\n",
    "    save_images(save_filename, save_dir) \n",
    "\n",
    "    \n",
    "save_fn_tsne = 'scanorama_tsne_10percent_kokds'\n",
    "plotTSNE(adata_ds, color_group, save_fn_tsne, save_fig_dir, npcs, perplex, False)\n",
    "print('Save output of t-SNE in :',save_fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output_tsne(adata, save_dir):   \n",
    "    colnt = []  # Save output of tsne for visualization\n",
    "    for i in range(adata.obsm['X_tsne'].shape[1]):\n",
    "        colnt.append(\"tSNE_\"+str(i+1))\n",
    "\n",
    "    df = pd.DataFrame(adata.obsm['X_tsne'], columns=colnt, index=adata.obs_names)\n",
    "    df['batch'] = pd.Series(adata.obs['batch'], index=adata.obs_names)\n",
    "#     df['batchlb'] = pd.Series(adata.obs['batchlb'], index=adata.obs_names)\n",
    "    df['celltype'] = pd.Series(adata.obs['cell_type'], index=adata.obs_names)\n",
    "    df.to_csv(save_dir+'scanorama_tsne.csv') \n",
    "\n",
    "    \n",
    "save_output_tsne(adata_ds, save_dir)\n",
    "print('Save output of normalized data in :',save_dir)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefn = 'scanorama_normalized_d8.h5ad'\n",
    "corrected_adata.write_h5ad(os.path.join(save_dir,savefn))\n",
    "print('Save output of normalized data in :',save_dir)\n",
    "\n",
    "# savefn = 'scanorama_normalized_adata8.h5ad'\n",
    "# adata.write_h5ad(os.path.join(save_dir,savefn))\n",
    "# print('Save output of normalized data in :',save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep scanorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
