{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.4+18.gaabe446 anndata==0.6.17 numpy==1.15.4 scipy==1.1.0 pandas==0.23.4 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 \n"
     ]
    }
   ],
   "source": [
    "# Scanorama batch effect correction\n",
    "# See more at: https://github.com/brianhie/scanorama\n",
    "# Hoa Tran \n",
    "# Update code from python version 2 to python version 3, Keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from matplotlib import rcParams\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import scanpy as sc\n",
    "sc.settings.verbosity = 3  # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/acrc/jinmiao/CJM_lab/hoatran/demo_normalization/demo_Scanorama/scanorama_python\n"
     ]
    }
   ],
   "source": [
    "# Create folder to save the results \n",
    "import os\n",
    "dirname = os.getcwd()\n",
    "print(dirname)\n",
    "\n",
    "if not os.path.exists('./results/'): os.makedirs('./results/')   \n",
    "if not os.path.exists('./results/results_dataset4_pancreatic/'): os.makedirs('./results/results_dataset4_pancreatic/')    \n",
    "save_dir = os.path.join(dirname, 'results/results_dataset4_pancreatic/')\n",
    "\n",
    "# Function to save figure as image in the figures folder\n",
    "save_fig_dir='./figures/dataset4_pancreatic/'\n",
    "if not os.path.exists('./figures/'): os.makedirs('./figures/')\n",
    "if not os.path.exists(save_fig_dir): os.makedirs(save_fig_dir)\n",
    "def save_images(filename, save_fig_dir):    \n",
    "    outname = save_fig_dir + filename + '.png'\n",
    "    pl.savefig(outname, dpi=150)\n",
    "    pl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, myDataFn, mySampleFn,save_dir, savefn, saveh5ad=False):\n",
    "    myData = pd.read_csv(os.path.join(data_dir,myDataFn),header=0, index_col=0, sep='\\t')\n",
    "    mySample = pd.read_csv(os.path.join(data_dir,mySampleFn),header=0, index_col=0, sep='\\t')\n",
    "    adata = sc.AnnData(myData.values.T)\n",
    "    adata.obs_names = myData.keys()\n",
    "    adata.var_names = myData.index\n",
    "    adata.obs['cell_type'] = mySample.loc[adata.obs_names,['celltype']]\n",
    "    adata.obs['batch'] = mySample.loc[adata.obs_names,['batch']]\n",
    "#     adata.obs['batch'] = adata.obs['batch'].astype('category')\n",
    "    adata.obs['batchlb'] = mySample.loc[adata.obs_names,['batchlb']]\n",
    "\n",
    "    # Save output into h5ad, lightweight, easy to access and load again\n",
    "    # Similar to rds format in R\n",
    "    if saveh5ad:\n",
    "        adata.write_h5ad(os.path.join(save_dir,savefn))\n",
    "        \n",
    "    print(adata)\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('/home/hoa/hoatran/demo_normalization/dataset/dataset4_human_pancreatic/raw_data_python/')\n",
    "\n",
    "# myDataFn = 'myData_pancreatic_5batches.txt'\n",
    "# mySampleFn = 'mySample_pancreatic_5batches.txt'\n",
    "savefn = 'myRawData1.h5ad'\n",
    "# adata = load_data(data_dir, myDataFn, mySampleFn, save_dir, savefn,saveh5ad=True)\n",
    "# print('Read and filter data')\n",
    "\n",
    "adata = sc.read_h5ad(os.path.join(data_dir,savefn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 14767 × 15558 \n",
       "    obs: 'cell_type', 'batch', 'batchlb'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 14767 × 15558 \n",
       "    obs: 'cell_type', 'batch', 'batchlb'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore this step for this dataset\n",
    "# Filtering data \n",
    "# adata\n",
    "# sc.pp.filter_cells(adata, min_genes=300)\n",
    "# sc.pp.filter_genes(adata, min_cells=10)\n",
    "\n",
    "# Not different in the case of Scanorama\n",
    "# sc.pp.log1p(adata)\n",
    "# sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_dup = adata.copy()\n",
    "sc.pp.normalize_per_cell(adata_dup)\n",
    "sc.pp.log1p(adata_dup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> added\n",
      "    'highly_variable', boolean vector (adata.var)\n",
      "    'means', float vector (adata.var)\n",
      "    'dispersions', float vector (adata.var)\n",
      "    'dispersions_norm', float vector (adata.var)\n",
      "[5000, 15558]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 14767 × 5000 \n",
       "    obs: 'cell_type', 'batch', 'batchlb'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.pp.highly_variable_genes(adata_dup, n_top_genes=5000, flavor='seurat')\n",
    "print([sum(adata_dup.var['highly_variable']),len(adata_dup.var['highly_variable'])])\n",
    "adata = adata[:,adata_dup.var['highly_variable']]\n",
    "adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 8569 × 5000 \n",
      "    obs: 'cell_type', 'batch', 'batchlb'\n",
      "AnnData object with n_obs × n_vars = 2122 × 5000 \n",
      "    obs: 'cell_type', 'batch', 'batchlb'\n",
      "AnnData object with n_obs × n_vars = 2127 × 5000 \n",
      "    obs: 'cell_type', 'batch', 'batchlb'\n",
      "AnnData object with n_obs × n_vars = 457 × 5000 \n",
      "    obs: 'cell_type', 'batch', 'batchlb'\n",
      "AnnData object with n_obs × n_vars = 1492 × 5000 \n",
      "    obs: 'cell_type', 'batch', 'batchlb'\n"
     ]
    }
   ],
   "source": [
    "from scanorama import correct, visualize, process_data\n",
    "from scanorama import dimensionality_reduce\n",
    "\n",
    "# Extract data from batch 1 and batch 2\n",
    "adata1_filtered = adata[adata.obs['batch']==1,:].copy()  # after concatenate, the values change from 1 to 0, 2 to 1\n",
    "print(adata1_filtered)\n",
    "adata2_filtered = adata[adata.obs['batch']==2,:].copy()\n",
    "print(adata2_filtered)\n",
    "adata3_filtered = adata[adata.obs['batch']==3,:].copy()\n",
    "print(adata3_filtered)\n",
    "adata4_filtered = adata[adata.obs['batch']==4,:].copy()\n",
    "print(adata4_filtered)\n",
    "adata5_filtered = adata[adata.obs['batch']==5,:].copy()\n",
    "print(adata5_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_ls = [adata1_filtered, adata2_filtered, adata3_filtered, adata4_filtered, adata5_filtered]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 genes among all datasets\n",
      "[[0.         0.20263902 0.348378   0.09846827 0.1963807 ]\n",
      " [0.         0.         0.63195099 0.27133479 0.01979265]\n",
      " [0.         0.         0.         0.73085339 0.26474531]\n",
      " [0.         0.         0.         0.         0.27613941]\n",
      " [0.         0.         0.         0.         0.        ]]\n",
      "Processing datasets (2, 3)\n",
      "Processing datasets (1, 2)\n",
      "Processing datasets (0, 2)\n",
      "Processing datasets (3, 4)\n",
      "Processing datasets (1, 3)\n",
      "Processing datasets (2, 4)\n",
      "Processing datasets (0, 1)\n",
      "Processing datasets (0, 4)\n",
      "Took 0:06:02.516935\n"
     ]
    }
   ],
   "source": [
    "import scanorama\n",
    "# Batch correction.\n",
    "# datasets = [df.values]\n",
    "# List of datasets (matrices of cells-by-genes)\n",
    "t1 = time.time()\n",
    "corrected = scanorama.correct_scanpy(adata_ls, batch_size=50, return_dense=True, knn=20)\n",
    "# corrected, genes = scanorama.correct(adata_ls, adata1.var_names,batch_size=30)\n",
    "t2 = time.time()\n",
    "print('Took '+str(timedelta(seconds=t2-t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 14767 × 5000 \n"
     ]
    }
   ],
   "source": [
    "total_ann = sc.AnnData(np.concatenate([corrected[0].X, corrected[1].X, corrected[2].X, corrected[3].X, corrected[4].X]))\n",
    "print(total_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['A4GALT', 'AAAS', 'AADAC', 'AARSD1'], dtype='object')\n",
      "Index(['0', '1', '2', '3', '4'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(corrected[0].var_names[1:5])\n",
    "# print(corrected[0].obs_names[0:10]==adata1_filtered.obs_names[0:10])\n",
    "# print(corrected[1])\n",
    "# print(corrected[1].obs_names[0:10]==adata2_filtered.obs_names[0:10])\n",
    "# print(corrected[2])\n",
    "# print(corrected[2].obs_names[0:10]==adata3_filtered.obs_names[0:10])\n",
    "# print(corrected[1])\n",
    "# print(corrected[3].obs_names[0:10]==adata4_filtered.obs_names[0:10])\n",
    "# print(corrected[4].obs_names[0:10]==adata5_filtered.obs_names[0:10])\n",
    "print(corrected[0].obs_names[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 14767 × 5000 \n",
       "    obs: 'cell_type', 'batch', 'batchlb'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ann.var_names = corrected[0].var_names\n",
    "total_ann.obs_names = adata1_filtered.obs_names.tolist() + adata2_filtered.obs_names.tolist() + adata3_filtered.obs_names.tolist() + adata4_filtered.obs_names.tolist() + adata5_filtered.obs_names.tolist()\n",
    "total_ann.obs['cell_type'] = adata1_filtered.obs['cell_type'].tolist() + adata2_filtered.obs['cell_type'].tolist() + adata3_filtered.obs['cell_type'].tolist() + adata4_filtered.obs['cell_type'].tolist() + adata5_filtered.obs['cell_type'].tolist()\n",
    "total_ann.obs['batch'] = adata1_filtered.obs['batch'].tolist() + adata2_filtered.obs['batch'].tolist() + adata3_filtered.obs['batch'].tolist() + adata4_filtered.obs['batch'].tolist() + adata5_filtered.obs['batch'].tolist()\n",
    "total_ann.obs['batchlb'] = adata1_filtered.obs['batchlb'].tolist() + adata2_filtered.obs['batchlb'].tolist() + adata3_filtered.obs['batchlb'].tolist() + adata4_filtered.obs['batchlb'].tolist() + adata5_filtered.obs['batchlb'].tolist()\n",
    "total_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(total_ann, svd_solver='arpack') # n_comps=20\n",
    "total_ann.obsm['X_pca'] *= -1  # multiply by -1 to match Seurat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took seconds: 0:06:03\n",
      "Took minutes: (6.0, 2.516935110092163)\n",
      "Took hours_minutes_seconds:  0.0 6.0 2.516935110092163\n",
      "                  use_case exetime_secs exetimehours exetimemins exetimesecs\n",
      "exetime  scanorama_exetime          363          0.0         6.0           3\n"
     ]
    }
   ],
   "source": [
    "def getExecutionTime(t1, t2, save_dir, usecase_name,filename):\n",
    "    time_taken = (t2 - t1)\n",
    "    time_taken_mins = divmod(time_taken, 60)\n",
    "    time_taken_hours, rest = divmod( time_taken, 3600)\n",
    "    hours_mins, hours_secs = divmod( rest, 60)\n",
    "    print('Took seconds: '+str(timedelta(seconds=round(time_taken))))\n",
    "    print('Took minutes: '+str(time_taken_mins))\n",
    "    print('Took hours_minutes_seconds: ',str(time_taken_hours),str(hours_mins),str(hours_secs))\n",
    "    \n",
    "    \n",
    "\n",
    "    data = {'use_case':usecase_name, 'exetime_secs':str(round(time_taken)),\n",
    "           'exetimehours': str(time_taken_hours),\n",
    "           'exetimemins': str(hours_mins),\n",
    "           'exetimesecs':str(round(hours_secs))} \n",
    "    df = pd.DataFrame(data, index =['exetime'])\n",
    "    print(df)\n",
    "    df.to_csv(save_dir+filename) \n",
    "\n",
    "# Evaluation runtime of main batch effect removal function\n",
    "filename = 'scanorama_exetime.csv'\n",
    "usecase_name = 'scanorama_exetime' \n",
    "getExecutionTime(t1, t2, save_dir, usecase_name, filename)  # t1: start time, t2: end time  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing neighbors\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    finished (0:00:09.85) --> added to `.uns['neighbors']`\n",
      "    'distances', distances for each pair of neighbors\n",
      "    'connectivities', weighted adjacency matrix\n",
      "computing UMAP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'cell_type' as categorical\n",
      "... storing 'batchlb' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    finished (0:00:17.33) --> added\n",
      "    'X_umap', UMAP coordinates (adata.obsm)\n",
      "computing tSNE\n",
      "    using 'X_pca' with n_pcs = 20\n",
      "    using the 'MulticoreTSNE' package by Ulyanov (2017)\n",
      "    finished (0:01:40.85) --> added\n",
      "    'X_tsne', tSNE coordinates (adata.obsm)\n"
     ]
    }
   ],
   "source": [
    "npcs = 20  # our pre-defined\n",
    "perplex = 30  # our pre-defined\n",
    "nb_neighbors = 15\n",
    "\n",
    "\n",
    "# def save_images(filename, save_fig_dir):    \n",
    "#     outname = save_fig_dir + filename + '.png'\n",
    "#     pl.savefig(outname, dpi=150)\n",
    "#     pl.close()\n",
    "    \n",
    "# Function to plot TSNE\n",
    "def plotTSNE(adata, color_group, save_filename='tsne', save_dir='', n_pcs=20, perplex=30, use_repx = False):\n",
    "    \n",
    "    # Run with all genes and entire matrix\n",
    "    if use_repx:\n",
    "        sc.tl.tsne(adata, perplexity=perplex, use_rep='X')\n",
    "    else:    # Run tsne using pcs vectors\n",
    "        sc.tl.tsne(adata, n_pcs=n_pcs, perplexity=perplex)\n",
    "    sc.pl.tsne(adata, color = color_group, show=False, wspace=.3)\n",
    "    save_images(save_filename, save_dir) \n",
    "    \n",
    "def plotUMAP(adata, color_group, save_filename='umap', save_dir='', npcs=20, nb_neighbors=15, use_repx = False):\n",
    "    \n",
    "    # Run with all genes and entire matrix\n",
    "    if use_repx:\n",
    "        sc.pp.neighbors(adata, use_rep='X')\n",
    "    else:    # Run umap using pcs vectors\n",
    "        sc.pp.neighbors(adata,n_neighbors=nb_neighbors, n_pcs=npcs)\n",
    "        \n",
    "    sc.tl.umap(adata)\n",
    "    sc.pl.umap(adata, color = color_group, show=False)\n",
    "    save_images(save_filename, save_dir)\n",
    "\n",
    "    \n",
    "color_group = [\"batchlb\",\"cell_type\"] \n",
    "save_fn_tsne = 'scanorama_tsne'\n",
    "save_fn_umap = 'scanorama_umap'\n",
    "plotUMAP(total_ann, color_group, save_fn_umap, save_fig_dir, npcs, nb_neighbors, False)\n",
    "plotTSNE(total_ann, color_group, save_fn_tsne, save_fig_dir, npcs, perplex, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_output(adata, save_dir): \n",
    "    colnu = []\n",
    "    for i in range(adata.obsm['X_umap'].shape[1]):\n",
    "        colnu.append(\"UMAP\"+str(i+1))\n",
    "    df = pd.DataFrame(adata.obsm['X_umap'], columns=colnu, index=adata.obs_names)\n",
    "    df['batch'] = pd.Series(adata.obs['batch'], index=adata.obs_names)\n",
    "    df['batchlb'] = pd.Series(adata.obs['batchlb'], index=adata.obs_names)\n",
    "    df['celltype'] = pd.Series(adata.obs['cell_type'], index=adata.obs_names)\n",
    "    df.to_csv(save_dir+'scanorama_umap.csv')  \n",
    "\n",
    "    # Save output of tsne for visualization\n",
    "    colnt = []\n",
    "    for i in range(adata.obsm['X_tsne'].shape[1]):\n",
    "        colnt.append(\"tSNE_\"+str(i+1))\n",
    "\n",
    "    df = pd.DataFrame(adata.obsm['X_tsne'], columns=colnt, index=adata.obs_names)\n",
    "    df['batch'] = pd.Series(adata.obs['batch'], index=adata.obs_names)\n",
    "    df['batchlb'] = pd.Series(adata.obs['batchlb'], index=adata.obs_names)\n",
    "    df['celltype'] = pd.Series(adata.obs['cell_type'], index=adata.obs_names)\n",
    "    df.to_csv(save_dir+'scanorama_tsne.csv') \n",
    "\n",
    "    # Save output of pca for evaluation ASW\n",
    "    colnpc = []\n",
    "    for i in range(20):\n",
    "        colnpc.append(\"X_pca\"+str(i+1))\n",
    "\n",
    "    df = pd.DataFrame(adata.obsm['X_pca'][:, :20], columns=colnpc, index=adata.obs_names)\n",
    "    df['batch'] = pd.Series(adata.obs['batch'], index=adata.obs_names)\n",
    "    df['batchlb'] = pd.Series(adata.obs['batchlb'], index=adata.obs_names)\n",
    "    df['celltype'] = pd.Series(adata.obs['cell_type'], index=adata.obs_names)\n",
    "    df.to_csv(save_dir+'scanorama_pca.csv')\n",
    "\n",
    "save_output(total_ann, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefn = 'scanorama_normalized_adata.h5ad'\n",
    "total_ann.write_h5ad(os.path.join(save_dir,savefn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
